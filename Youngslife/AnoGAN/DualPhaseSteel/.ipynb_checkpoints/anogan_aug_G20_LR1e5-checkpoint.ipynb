{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnoGAN\n",
    "- 2020.08.11 : Genrator 학습 수 ... 4\n",
    "\n",
    "# 개발일지\n",
    "- 2020.08.14 : 분율 추출 구현\n",
    "- 2020.08.15 : 이상치 상관계수 추출 구현 / 모델 save, load 구현\n",
    "- 2020.08.16 : anomaly detect 이미지 저장 구현 / 티티늄(Ti64) 상대 밀도 계산 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# Graph & Animation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 100 # z벡터의 잠재공간(latent space)의 크기\n",
    "workers = 4 # 0일때, 약 20% 사용 4일 경우 메모리 100%\n",
    "img_size = 64\n",
    "channel = 1\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dataset : 920\n",
      "device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 이미지 경로, 이미지들 리사이즈 및 텐서형태로 만들기\n",
    "data_root = \"../../../OhSeHyeon/source/dataset/aug_train\"\n",
    "\n",
    "data_set = dataset.ImageFolder(root = data_root,\n",
    "                           transform = transforms.Compose([\n",
    "                                  #transforms.Resize(img_size),\n",
    "                                  transforms.CenterCrop(img_size),\n",
    "                                  torchvision.transforms.Grayscale(channel),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5,),(0.5,))\n",
    "                              ]))\n",
    "\n",
    "print(\"size of dataset :\", len(data_set))\n",
    "\n",
    "# 배치로 나누고 셔플하기\n",
    "data_loader = torch.utils.data.DataLoader(data_set, batch_size = batch_size,\n",
    "                                         shuffle = True, num_workers = workers, drop_last=True)\n",
    "\n",
    "# Device setting (GPU or CPU)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device :\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative Adversarial Networks Model\n",
    "\n",
    "# === Generator 모델 ===\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        \n",
    "        # Batch Normalization 유무에 따른 G_block 정의\n",
    "        def G_block(in_features, out_features, FIRST=True):\n",
    "            if FIRST:\n",
    "                block = [\n",
    "                    nn.ConvTranspose2d(in_features, out_features, 4, 1, 0, bias=False),\n",
    "                    nn.BatchNorm2d(out_features),\n",
    "                    nn.ReLU()\n",
    "                ]\n",
    "            else:\n",
    "                block = [\n",
    "                    nn.ConvTranspose2d(in_features, out_features, 4, 2, 1, bias=False),\n",
    "                    nn.BatchNorm2d(out_features),\n",
    "                    nn.ReLU()\n",
    "                ]\n",
    "            return block\n",
    "        \n",
    "        \n",
    "        # ======================= 픽셀 분포 생성 layer ======================= \n",
    "        self.G_gen_distribution = nn.Sequential(\n",
    "            # ------ input is latent_size 100 ------ \n",
    "            *G_block(latent_size, img_size*8, FIRST=True),\n",
    "            # ------ state size is 512x4x4 ------ \n",
    "            *G_block(img_size*8, img_size*4, FIRST=False),\n",
    "            # ------ state size is 256x8x8 ------ \n",
    "            *G_block(img_size*4, img_size*2, FIRST=False),\n",
    "            # ------ state size is 128x16x16 ------ \n",
    "            *G_block(img_size*2, img_size, FIRST=False),\n",
    "        )\n",
    "        \n",
    "        # =================== 가짜 이미지 생성 layer =================== \n",
    "        self.G_gen_fake_img = nn.Sequential(\n",
    "            # ------ state size is 64x32x32 ------ \n",
    "            nn.ConvTranspose2d(img_size, 1 , 4, 2, 1, bias=False),\n",
    "            nn.Tanh() # 픽셀값의 범위 : -1 ~ 1로 두기 위해서\n",
    "            # ------ state size is 1x64x64 ------ \n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        distribution = self.G_gen_distribution(input)\n",
    "        fake_img = self.G_gen_fake_img(distribution)\n",
    "        \n",
    "        return fake_img\n",
    "\n",
    "\n",
    "# === Discriminator 모델 ===\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Batch Normalization 유무에 따른 D_block 정의\n",
    "        def D_block(in_features, out_features, BN=True):\n",
    "            if BN:\n",
    "                block = [\n",
    "                    nn.Conv2d(in_features, out_features, 4, 2, 1, bias=False),\n",
    "                    nn.BatchNorm2d(out_features),\n",
    "                    nn.LeakyReLU(0.2, inplace=True)\n",
    "                ]\n",
    "            else:\n",
    "                block = [\n",
    "                    nn.Conv2d(in_features, out_features, 4, 2, 1, bias=False),\n",
    "                    nn.LeakyReLU(0.2, inplace=True)\n",
    "                ]\n",
    "            return block\n",
    "        \n",
    "        \n",
    "        # ============== Feature 추출 layer ==============\n",
    "        self.D_extract_feature = nn.Sequential(\n",
    "            # ------ input is 1 x 64 x 64 ------ \n",
    "            *D_block(channel, img_size, BN=False),\n",
    "            # ------ state is 64 x 32 x 32 ------ \n",
    "            *D_block(img_size, img_size*2, BN=True),\n",
    "            # ------ state is 128 x 16 x 16 ------ \n",
    "            *D_block(img_size*2, img_size*4, BN=True),\n",
    "            # ------ state is 256 x 8 x 8 ------ \n",
    "            *D_block(img_size*4, img_size*8, BN=True)\n",
    "        )\n",
    "        \n",
    "        # ===================== 이진 분류 layer =====================\n",
    "        self.D_classification = nn.Sequential(        \n",
    "            # ------- state size 512x4x4 ------- \n",
    "            nn.Conv2d(img_size*8, channel, 4, 1, 0, bias=False),\n",
    "            #nn.Linear(fms*8*4*4, 1, bias=False),\n",
    "            nn.Sigmoid()        \n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        feature = self.D_extract_feature(input)\n",
    "        classification = self.D_classification(feature)\n",
    "        \n",
    "        return classification, feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss & Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G and D 무게 초기화, classname 에 찾는 name가 없다면 -1 ,\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "# D,G 네트워크 모델 객체 선언\n",
    "D = Discriminator().to(device)\n",
    "G = Generator().to(device)\n",
    "\n",
    "# weight initialize/ nn.Module 클래스 안에 apply 함수가 정의되 있음, 각 함수들에 다 적용 하게한다\n",
    "D.apply(weights_init)\n",
    "G.apply(weights_init)\n",
    "\n",
    "# Binary cross entropy loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# latent vector에 배치 사이즈 64를 적용\n",
    "# 학습한 G로 새로운 것 만들어서 결과 확인 할때 사용\n",
    "noise_z = torch.randn(img_size, latent_size, 1, 1, device = device)\n",
    "\n",
    "# D와 G에 대해 두가지 최적화 설정\n",
    "D_optimizer = torch.optim.Adam(D.parameters(), lr = learning_rate, betas=(0.5,0.999))\n",
    "G_optimizer = torch.optim.Adam(G.parameters(), lr = learning_rate, betas=(0.5,0.999))\n",
    "\n",
    "#print(D)\n",
    "#print(G)\n",
    "\n",
    "def reset_grad():\n",
    "    D_optimizer.zero_grad()\n",
    "    G_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "def train(epoch, learning_G_per_D):\n",
    "    global epochs\n",
    "    global iters\n",
    "    \n",
    "    # 인덱스 0부터 세기 시작\n",
    "    # data[0].size():64x1x64x64(image) / data[1].size():64(label)\n",
    "    for i,data in enumerate(data_loader,0):\n",
    "        \n",
    "        # Train Discriminator\n",
    "        real_img = data[0].to(device) # image size: 64x1x64x64(batch, channel, width, height)\n",
    "        b_size = real_img.size(0) # b_size = 64\n",
    "        real_labels = torch.ones(b_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(b_size, 1).to(device)\n",
    "        \n",
    "        # (--------------------------real-----------------------------)\n",
    "        real_classification, _ = D(real_img) # output = D(x)\n",
    "        real_loss = criterion(real_classification, real_labels) # D(x)=1일 때의 loss\n",
    "        real_score = real_classification\n",
    "        D_x = real_score.mean().item() \n",
    "            \n",
    "        # (--------------------------fake-----------------------------)\n",
    "        z = torch.randn(b_size, latent_size, 1, 1).to(device) # z size :64x100x1x1\n",
    "        fake_img = G(z)\n",
    "        fake_classification, _ = D(fake_img) # output = D(G(z))\n",
    "        fake_loss = criterion(fake_classification, fake_labels) # D(G(z))=0일 때의 loss\n",
    "        fake_score = fake_classification\n",
    "        D_G_z1 = fake_score.mean().item()\n",
    "\n",
    "        # (------------------Backprop and optimize---------------------)\n",
    "        D_loss = real_loss + fake_loss \n",
    "        reset_grad()\n",
    "        D_loss.backward()\n",
    "        D_optimizer.step() # D(x)=1, D(G(z))=0이어야 D가 최적\n",
    "\n",
    "        \n",
    "        # Train Generater\n",
    "        #z = torch.randn(b_size,latent_size,1,1,device=device) # z size :64x100x1x1\n",
    "        for k in range(learning_G_per_D):\n",
    "            fake_img = G(z)\n",
    "            fake_classification, _ = D(fake_img)  # output : D(G(z))\n",
    "            D_G_z2 = fake_classification.mean().item()\n",
    "            G_loss = criterion(fake_classification, real_labels) # D(G(z))=1일 때의 loss=log(D(G(z)))\n",
    "\n",
    "            # (------------------Backprop and optimize---------------------)\n",
    "            reset_grad()\n",
    "            G_loss.backward()\n",
    "            G_optimizer.step() # D(G(z))=1 이어야 G가 최적\n",
    "            # ==> D(G(z))의 값이 0.5로 수렴해야 한다.\n",
    "        \n",
    "        \n",
    "        # print\n",
    "        print('[%d/%d][%d/%d]\\n- D_loss : %.4f / G_loss : %.4f\\n- D(x) : %.4f / D(G(z1)) : %.4f / D(G(z2)) : %.4f' \n",
    "                   %(epoch+1, epochs, i, len(data_loader),D_loss.item(),\n",
    "                     G_loss.item(),D_x,D_G_z1,D_G_z2))\n",
    "        \n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(G_loss.item())\n",
    "        D_losses.append(D_loss.item())\n",
    "        \n",
    "        #Check how the generator is doing by saving G's output on noise_z\n",
    "        if (iters % 500 == 0) or ((epoch == epochs-1) and (i == len(data_loader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = G(noise_z).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "            \n",
    "        iters += 1\n",
    "        \n",
    "#torch.save(G.state_dict(), 'G.ckpt')\n",
    "#torch.save(D.state_dict(), 'D.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piai/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64, 1, 1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100][0/14]\n",
      "- D_loss : 1.3852 / G_loss : 0.6693\n",
      "- D(x) : 0.4991 / D(G(z1)) : 0.4985 / D(G(z2)) : 0.5121\n",
      "[1/100][1/14]\n",
      "- D_loss : 1.3943 / G_loss : 0.6546\n",
      "- D(x) : 0.4991 / D(G(z1)) : 0.5031 / D(G(z2)) : 0.5197\n",
      "[1/100][2/14]\n",
      "- D_loss : 1.4034 / G_loss : 0.6430\n",
      "- D(x) : 0.5005 / D(G(z1)) : 0.5089 / D(G(z2)) : 0.5257\n",
      "[1/100][3/14]\n",
      "- D_loss : 1.4167 / G_loss : 0.6301\n",
      "- D(x) : 0.5009 / D(G(z1)) : 0.5158 / D(G(z2)) : 0.5326\n",
      "[1/100][4/14]\n",
      "- D_loss : 1.4277 / G_loss : 0.6197\n",
      "- D(x) : 0.5021 / D(G(z1)) : 0.5223 / D(G(z2)) : 0.5381\n",
      "[1/100][5/14]\n",
      "- D_loss : 1.4424 / G_loss : 0.6095\n",
      "- D(x) : 0.5017 / D(G(z1)) : 0.5289 / D(G(z2)) : 0.5437\n",
      "[1/100][6/14]\n",
      "- D_loss : 1.4557 / G_loss : 0.5970\n",
      "- D(x) : 0.5033 / D(G(z1)) : 0.5365 / D(G(z2)) : 0.5505\n",
      "[1/100][7/14]\n",
      "- D_loss : 1.4688 / G_loss : 0.5888\n",
      "- D(x) : 0.5030 / D(G(z1)) : 0.5423 / D(G(z2)) : 0.5550\n",
      "[1/100][8/14]\n",
      "- D_loss : 1.4834 / G_loss : 0.5788\n",
      "- D(x) : 0.5029 / D(G(z1)) : 0.5488 / D(G(z2)) : 0.5606\n",
      "[1/100][9/14]\n",
      "- D_loss : 1.4943 / G_loss : 0.5700\n",
      "- D(x) : 0.5040 / D(G(z1)) : 0.5547 / D(G(z2)) : 0.5655\n",
      "[1/100][10/14]\n",
      "- D_loss : 1.5041 / G_loss : 0.5622\n",
      "- D(x) : 0.5051 / D(G(z1)) : 0.5600 / D(G(z2)) : 0.5699\n",
      "[1/100][11/14]\n",
      "- D_loss : 1.5185 / G_loss : 0.5543\n",
      "- D(x) : 0.5045 / D(G(z1)) : 0.5658 / D(G(z2)) : 0.5745\n",
      "[1/100][12/14]\n",
      "- D_loss : 1.5278 / G_loss : 0.5481\n",
      "- D(x) : 0.5048 / D(G(z1)) : 0.5700 / D(G(z2)) : 0.5781\n",
      "[1/100][13/14]\n",
      "- D_loss : 1.5347 / G_loss : 0.5416\n",
      "- D(x) : 0.5061 / D(G(z1)) : 0.5741 / D(G(z2)) : 0.5818\n",
      "[2/100][0/14]\n",
      "- D_loss : 1.5435 / G_loss : 0.5367\n",
      "- D(x) : 0.5062 / D(G(z1)) : 0.5779 / D(G(z2)) : 0.5847\n",
      "[2/100][1/14]\n",
      "- D_loss : 1.5517 / G_loss : 0.5328\n",
      "- D(x) : 0.5057 / D(G(z1)) : 0.5809 / D(G(z2)) : 0.5870\n",
      "[2/100][2/14]\n",
      "- D_loss : 1.5572 / G_loss : 0.5285\n",
      "- D(x) : 0.5061 / D(G(z1)) : 0.5836 / D(G(z2)) : 0.5895\n",
      "[2/100][3/14]\n",
      "- D_loss : 1.5650 / G_loss : 0.5238\n",
      "- D(x) : 0.5062 / D(G(z1)) : 0.5869 / D(G(z2)) : 0.5923\n",
      "[2/100][4/14]\n",
      "- D_loss : 1.5717 / G_loss : 0.5204\n",
      "- D(x) : 0.5060 / D(G(z1)) : 0.5895 / D(G(z2)) : 0.5943\n",
      "[2/100][5/14]\n",
      "- D_loss : 1.5755 / G_loss : 0.5177\n",
      "- D(x) : 0.5065 / D(G(z1)) : 0.5915 / D(G(z2)) : 0.5959\n",
      "[2/100][6/14]\n",
      "- D_loss : 1.5775 / G_loss : 0.5151\n",
      "- D(x) : 0.5075 / D(G(z1)) : 0.5930 / D(G(z2)) : 0.5975\n",
      "[2/100][7/14]\n",
      "- D_loss : 1.5830 / G_loss : 0.5120\n",
      "- D(x) : 0.5073 / D(G(z1)) : 0.5951 / D(G(z2)) : 0.5993\n",
      "[2/100][8/14]\n",
      "- D_loss : 1.5873 / G_loss : 0.5101\n",
      "- D(x) : 0.5070 / D(G(z1)) : 0.5966 / D(G(z2)) : 0.6005\n",
      "[2/100][9/14]\n",
      "- D_loss : 1.5875 / G_loss : 0.5077\n",
      "- D(x) : 0.5087 / D(G(z1)) : 0.5981 / D(G(z2)) : 0.6019\n",
      "[2/100][10/14]\n",
      "- D_loss : 1.5960 / G_loss : 0.5059\n",
      "- D(x) : 0.5063 / D(G(z1)) : 0.5995 / D(G(z2)) : 0.6030\n",
      "[2/100][11/14]\n",
      "- D_loss : 1.5962 / G_loss : 0.5048\n",
      "- D(x) : 0.5074 / D(G(z1)) : 0.6005 / D(G(z2)) : 0.6036\n",
      "[2/100][12/14]\n",
      "- D_loss : 1.5951 / G_loss : 0.5039\n",
      "- D(x) : 0.5082 / D(G(z1)) : 0.6007 / D(G(z2)) : 0.6042\n",
      "[2/100][13/14]\n",
      "- D_loss : 1.5995 / G_loss : 0.5017\n",
      "- D(x) : 0.5081 / D(G(z1)) : 0.6024 / D(G(z2)) : 0.6055\n",
      "[3/100][0/14]\n",
      "- D_loss : 1.5990 / G_loss : 0.5017\n",
      "- D(x) : 0.5086 / D(G(z1)) : 0.6026 / D(G(z2)) : 0.6055\n",
      "[3/100][1/14]\n",
      "- D_loss : 1.6014 / G_loss : 0.5002\n",
      "- D(x) : 0.5086 / D(G(z1)) : 0.6036 / D(G(z2)) : 0.6064\n",
      "[3/100][2/14]\n",
      "- D_loss : 1.5998 / G_loss : 0.4997\n",
      "- D(x) : 0.5098 / D(G(z1)) : 0.6038 / D(G(z2)) : 0.6067\n",
      "[3/100][3/14]\n",
      "- D_loss : 1.6058 / G_loss : 0.4984\n",
      "- D(x) : 0.5080 / D(G(z1)) : 0.6048 / D(G(z2)) : 0.6075\n",
      "[3/100][4/14]\n",
      "- D_loss : 1.6039 / G_loss : 0.4977\n",
      "- D(x) : 0.5099 / D(G(z1)) : 0.6055 / D(G(z2)) : 0.6080\n",
      "[3/100][5/14]\n",
      "- D_loss : 1.6047 / G_loss : 0.4979\n",
      "- D(x) : 0.5091 / D(G(z1)) : 0.6052 / D(G(z2)) : 0.6078\n",
      "[3/100][6/14]\n",
      "- D_loss : 1.6023 / G_loss : 0.4981\n",
      "- D(x) : 0.5103 / D(G(z1)) : 0.6052 / D(G(z2)) : 0.6077\n",
      "[3/100][7/14]\n",
      "- D_loss : 1.6038 / G_loss : 0.4972\n",
      "- D(x) : 0.5104 / D(G(z1)) : 0.6058 / D(G(z2)) : 0.6082\n",
      "[3/100][8/14]\n",
      "- D_loss : 1.6039 / G_loss : 0.4975\n",
      "- D(x) : 0.5100 / D(G(z1)) : 0.6056 / D(G(z2)) : 0.6080\n",
      "[3/100][9/14]\n",
      "- D_loss : 1.6064 / G_loss : 0.4968\n",
      "- D(x) : 0.5093 / D(G(z1)) : 0.6061 / D(G(z2)) : 0.6085\n",
      "[3/100][10/14]\n",
      "- D_loss : 1.6086 / G_loss : 0.4962\n",
      "- D(x) : 0.5083 / D(G(z1)) : 0.6062 / D(G(z2)) : 0.6089\n",
      "[3/100][11/14]\n",
      "- D_loss : 1.6059 / G_loss : 0.4961\n",
      "- D(x) : 0.5098 / D(G(z1)) : 0.6063 / D(G(z2)) : 0.6089\n",
      "[3/100][12/14]\n",
      "- D_loss : 1.6021 / G_loss : 0.4963\n",
      "- D(x) : 0.5116 / D(G(z1)) : 0.6061 / D(G(z2)) : 0.6088\n",
      "[3/100][13/14]\n",
      "- D_loss : 1.6089 / G_loss : 0.4949\n",
      "- D(x) : 0.5094 / D(G(z1)) : 0.6071 / D(G(z2)) : 0.6097\n",
      "[4/100][0/14]\n",
      "- D_loss : 1.6067 / G_loss : 0.4940\n",
      "- D(x) : 0.5108 / D(G(z1)) : 0.6073 / D(G(z2)) : 0.6102\n",
      "[4/100][1/14]\n",
      "- D_loss : 1.6087 / G_loss : 0.4926\n",
      "- D(x) : 0.5103 / D(G(z1)) : 0.6077 / D(G(z2)) : 0.6110\n",
      "[4/100][2/14]\n",
      "- D_loss : 1.6063 / G_loss : 0.4927\n",
      "- D(x) : 0.5113 / D(G(z1)) : 0.6075 / D(G(z2)) : 0.6110\n",
      "[4/100][3/14]\n",
      "- D_loss : 1.6088 / G_loss : 0.4908\n",
      "- D(x) : 0.5117 / D(G(z1)) : 0.6088 / D(G(z2)) : 0.6122\n",
      "[4/100][4/14]\n",
      "- D_loss : 1.6128 / G_loss : 0.4899\n",
      "- D(x) : 0.5105 / D(G(z1)) : 0.6094 / D(G(z2)) : 0.6127\n",
      "[4/100][5/14]\n",
      "- D_loss : 1.6114 / G_loss : 0.4893\n",
      "- D(x) : 0.5108 / D(G(z1)) : 0.6091 / D(G(z2)) : 0.6130\n",
      "[4/100][6/14]\n",
      "- D_loss : 1.6115 / G_loss : 0.4893\n",
      "- D(x) : 0.5115 / D(G(z1)) : 0.6097 / D(G(z2)) : 0.6131\n",
      "[4/100][7/14]\n",
      "- D_loss : 1.6123 / G_loss : 0.4885\n",
      "- D(x) : 0.5119 / D(G(z1)) : 0.6104 / D(G(z2)) : 0.6135\n",
      "[4/100][8/14]\n",
      "- D_loss : 1.6089 / G_loss : 0.4890\n",
      "- D(x) : 0.5120 / D(G(z1)) : 0.6090 / D(G(z2)) : 0.6133\n",
      "[4/100][9/14]\n",
      "- D_loss : 1.6131 / G_loss : 0.4882\n",
      "- D(x) : 0.5110 / D(G(z1)) : 0.6100 / D(G(z2)) : 0.6137\n",
      "[4/100][10/14]\n",
      "- D_loss : 1.6121 / G_loss : 0.4876\n",
      "- D(x) : 0.5113 / D(G(z1)) : 0.6098 / D(G(z2)) : 0.6141\n",
      "[4/100][11/14]\n",
      "- D_loss : 1.6117 / G_loss : 0.4866\n",
      "- D(x) : 0.5127 / D(G(z1)) : 0.6107 / D(G(z2)) : 0.6147\n",
      "[4/100][12/14]\n",
      "- D_loss : 1.6149 / G_loss : 0.4860\n",
      "- D(x) : 0.5119 / D(G(z1)) : 0.6113 / D(G(z2)) : 0.6151\n",
      "[4/100][13/14]\n",
      "- D_loss : 1.6144 / G_loss : 0.4864\n",
      "- D(x) : 0.5115 / D(G(z1)) : 0.6108 / D(G(z2)) : 0.6148\n",
      "[5/100][0/14]\n",
      "- D_loss : 1.6147 / G_loss : 0.4858\n",
      "- D(x) : 0.5111 / D(G(z1)) : 0.6107 / D(G(z2)) : 0.6152\n",
      "[5/100][1/14]\n",
      "- D_loss : 1.6127 / G_loss : 0.4843\n",
      "- D(x) : 0.5135 / D(G(z1)) : 0.6117 / D(G(z2)) : 0.6162\n",
      "[5/100][2/14]\n",
      "- D_loss : 1.6146 / G_loss : 0.4841\n",
      "- D(x) : 0.5126 / D(G(z1)) : 0.6117 / D(G(z2)) : 0.6163\n",
      "[5/100][3/14]\n",
      "- D_loss : 1.6182 / G_loss : 0.4830\n",
      "- D(x) : 0.5119 / D(G(z1)) : 0.6126 / D(G(z2)) : 0.6170\n",
      "[5/100][4/14]\n",
      "- D_loss : 1.6179 / G_loss : 0.4815\n",
      "- D(x) : 0.5124 / D(G(z1)) : 0.6128 / D(G(z2)) : 0.6179\n",
      "[5/100][5/14]\n",
      "- D_loss : 1.6199 / G_loss : 0.4787\n",
      "- D(x) : 0.5133 / D(G(z1)) : 0.6143 / D(G(z2)) : 0.6196\n",
      "[5/100][6/14]\n",
      "- D_loss : 1.6271 / G_loss : 0.4766\n",
      "- D(x) : 0.5118 / D(G(z1)) : 0.6159 / D(G(z2)) : 0.6209\n",
      "[5/100][7/14]\n",
      "- D_loss : 1.6244 / G_loss : 0.4752\n",
      "- D(x) : 0.5135 / D(G(z1)) : 0.6162 / D(G(z2)) : 0.6218\n",
      "[5/100][8/14]\n",
      "- D_loss : 1.6255 / G_loss : 0.4734\n",
      "- D(x) : 0.5155 / D(G(z1)) : 0.6180 / D(G(z2)) : 0.6229\n",
      "[5/100][9/14]\n",
      "- D_loss : 1.6321 / G_loss : 0.4713\n",
      "- D(x) : 0.5142 / D(G(z1)) : 0.6197 / D(G(z2)) : 0.6242\n",
      "[5/100][10/14]\n",
      "- D_loss : 1.6355 / G_loss : 0.4700\n",
      "- D(x) : 0.5131 / D(G(z1)) : 0.6201 / D(G(z2)) : 0.6250\n",
      "[5/100][11/14]\n",
      "- D_loss : 1.6372 / G_loss : 0.4695\n",
      "- D(x) : 0.5122 / D(G(z1)) : 0.6200 / D(G(z2)) : 0.6254\n",
      "[5/100][12/14]\n",
      "- D_loss : 1.6424 / G_loss : 0.4678\n",
      "- D(x) : 0.5120 / D(G(z1)) : 0.6219 / D(G(z2)) : 0.6264\n",
      "[5/100][13/14]\n",
      "- D_loss : 1.6438 / G_loss : 0.4664\n",
      "- D(x) : 0.5125 / D(G(z1)) : 0.6228 / D(G(z2)) : 0.6272\n",
      "[6/100][0/14]\n",
      "- D_loss : 1.6452 / G_loss : 0.4655\n",
      "- D(x) : 0.5123 / D(G(z1)) : 0.6232 / D(G(z2)) : 0.6278\n",
      "[6/100][1/14]\n",
      "- D_loss : 1.6435 / G_loss : 0.4637\n",
      "- D(x) : 0.5148 / D(G(z1)) : 0.6244 / D(G(z2)) : 0.6290\n",
      "[6/100][2/14]\n",
      "- D_loss : 1.6414 / G_loss : 0.4623\n",
      "- D(x) : 0.5164 / D(G(z1)) : 0.6247 / D(G(z2)) : 0.6298\n",
      "[6/100][3/14]\n",
      "- D_loss : 1.6489 / G_loss : 0.4602\n",
      "- D(x) : 0.5143 / D(G(z1)) : 0.6260 / D(G(z2)) : 0.6312\n",
      "[6/100][4/14]\n",
      "- D_loss : 1.6545 / G_loss : 0.4586\n",
      "- D(x) : 0.5130 / D(G(z1)) : 0.6272 / D(G(z2)) : 0.6322\n",
      "[6/100][5/14]\n",
      "- D_loss : 1.6577 / G_loss : 0.4568\n",
      "- D(x) : 0.5136 / D(G(z1)) : 0.6289 / D(G(z2)) : 0.6333\n",
      "[6/100][6/14]\n",
      "- D_loss : 1.6583 / G_loss : 0.4553\n",
      "- D(x) : 0.5143 / D(G(z1)) : 0.6295 / D(G(z2)) : 0.6342\n",
      "[6/100][7/14]\n",
      "- D_loss : 1.6615 / G_loss : 0.4533\n",
      "- D(x) : 0.5147 / D(G(z1)) : 0.6309 / D(G(z2)) : 0.6356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/100][8/14]\n",
      "- D_loss : 1.6683 / G_loss : 0.4519\n",
      "- D(x) : 0.5125 / D(G(z1)) : 0.6320 / D(G(z2)) : 0.6365\n",
      "[6/100][9/14]\n",
      "- D_loss : 1.6654 / G_loss : 0.4513\n",
      "- D(x) : 0.5145 / D(G(z1)) : 0.6323 / D(G(z2)) : 0.6368\n",
      "[6/100][10/14]\n",
      "- D_loss : 1.6706 / G_loss : 0.4497\n",
      "- D(x) : 0.5136 / D(G(z1)) : 0.6335 / D(G(z2)) : 0.6378\n",
      "[6/100][11/14]\n",
      "- D_loss : 1.6705 / G_loss : 0.4499\n",
      "- D(x) : 0.5142 / D(G(z1)) : 0.6340 / D(G(z2)) : 0.6377\n",
      "[6/100][12/14]\n",
      "- D_loss : 1.6725 / G_loss : 0.4493\n",
      "- D(x) : 0.5141 / D(G(z1)) : 0.6346 / D(G(z2)) : 0.6381\n",
      "[6/100][13/14]\n",
      "- D_loss : 1.6731 / G_loss : 0.4493\n",
      "- D(x) : 0.5139 / D(G(z1)) : 0.6347 / D(G(z2)) : 0.6381\n",
      "[7/100][0/14]\n",
      "- D_loss : 1.6720 / G_loss : 0.4492\n",
      "- D(x) : 0.5144 / D(G(z1)) : 0.6347 / D(G(z2)) : 0.6382\n",
      "[7/100][1/14]\n",
      "- D_loss : 1.6745 / G_loss : 0.4485\n",
      "- D(x) : 0.5139 / D(G(z1)) : 0.6353 / D(G(z2)) : 0.6386\n",
      "[7/100][2/14]\n",
      "- D_loss : 1.6732 / G_loss : 0.4476\n",
      "- D(x) : 0.5157 / D(G(z1)) : 0.6360 / D(G(z2)) : 0.6392\n",
      "[7/100][3/14]\n",
      "- D_loss : 1.6764 / G_loss : 0.4472\n",
      "- D(x) : 0.5140 / D(G(z1)) : 0.6360 / D(G(z2)) : 0.6395\n",
      "[7/100][4/14]\n",
      "- D_loss : 1.6743 / G_loss : 0.4466\n",
      "- D(x) : 0.5153 / D(G(z1)) : 0.6361 / D(G(z2)) : 0.6398\n",
      "[7/100][5/14]\n",
      "- D_loss : 1.6774 / G_loss : 0.4459\n",
      "- D(x) : 0.5150 / D(G(z1)) : 0.6371 / D(G(z2)) : 0.6403\n",
      "[7/100][6/14]\n",
      "- D_loss : 1.6768 / G_loss : 0.4460\n",
      "- D(x) : 0.5155 / D(G(z1)) : 0.6372 / D(G(z2)) : 0.6402\n",
      "[7/100][7/14]\n",
      "- D_loss : 1.6760 / G_loss : 0.4462\n",
      "- D(x) : 0.5158 / D(G(z1)) : 0.6371 / D(G(z2)) : 0.6401\n",
      "[7/100][8/14]\n",
      "- D_loss : 1.6777 / G_loss : 0.4457\n",
      "- D(x) : 0.5156 / D(G(z1)) : 0.6376 / D(G(z2)) : 0.6404\n",
      "[7/100][9/14]\n",
      "- D_loss : 1.6792 / G_loss : 0.4454\n",
      "- D(x) : 0.5153 / D(G(z1)) : 0.6380 / D(G(z2)) : 0.6406\n",
      "[7/100][10/14]\n",
      "- D_loss : 1.6794 / G_loss : 0.4457\n",
      "- D(x) : 0.5144 / D(G(z1)) : 0.6373 / D(G(z2)) : 0.6404\n",
      "[7/100][11/14]\n",
      "- D_loss : 1.6770 / G_loss : 0.4458\n",
      "- D(x) : 0.5157 / D(G(z1)) : 0.6374 / D(G(z2)) : 0.6404\n",
      "[7/100][12/14]\n",
      "- D_loss : 1.6766 / G_loss : 0.4457\n",
      "- D(x) : 0.5157 / D(G(z1)) : 0.6373 / D(G(z2)) : 0.6404\n",
      "[7/100][13/14]\n",
      "- D_loss : 1.6789 / G_loss : 0.4456\n",
      "- D(x) : 0.5151 / D(G(z1)) : 0.6377 / D(G(z2)) : 0.6404\n",
      "[8/100][0/14]\n",
      "- D_loss : 1.6779 / G_loss : 0.4460\n",
      "- D(x) : 0.5152 / D(G(z1)) : 0.6374 / D(G(z2)) : 0.6402\n",
      "[8/100][1/14]\n",
      "- D_loss : 1.6750 / G_loss : 0.4466\n",
      "- D(x) : 0.5164 / D(G(z1)) : 0.6372 / D(G(z2)) : 0.6398\n",
      "[8/100][2/14]\n",
      "- D_loss : 1.6773 / G_loss : 0.4468\n",
      "- D(x) : 0.5153 / D(G(z1)) : 0.6372 / D(G(z2)) : 0.6397\n",
      "[8/100][3/14]\n",
      "- D_loss : 1.6770 / G_loss : 0.4473\n",
      "- D(x) : 0.5151 / D(G(z1)) : 0.6370 / D(G(z2)) : 0.6393\n",
      "[8/100][4/14]\n",
      "- D_loss : 1.6748 / G_loss : 0.4482\n",
      "- D(x) : 0.5154 / D(G(z1)) : 0.6364 / D(G(z2)) : 0.6388\n",
      "[8/100][5/14]\n",
      "- D_loss : 1.6703 / G_loss : 0.4483\n",
      "- D(x) : 0.5174 / D(G(z1)) : 0.6361 / D(G(z2)) : 0.6387\n",
      "[8/100][6/14]\n",
      "- D_loss : 1.6717 / G_loss : 0.4486\n",
      "- D(x) : 0.5161 / D(G(z1)) : 0.6358 / D(G(z2)) : 0.6385\n",
      "[8/100][7/14]\n",
      "- D_loss : 1.6718 / G_loss : 0.4488\n",
      "- D(x) : 0.5161 / D(G(z1)) : 0.6358 / D(G(z2)) : 0.6384\n",
      "[8/100][8/14]\n",
      "- D_loss : 1.6701 / G_loss : 0.4489\n",
      "- D(x) : 0.5172 / D(G(z1)) : 0.6360 / D(G(z2)) : 0.6384\n",
      "[8/100][9/14]\n",
      "- D_loss : 1.6732 / G_loss : 0.4493\n",
      "- D(x) : 0.5151 / D(G(z1)) : 0.6356 / D(G(z2)) : 0.6381\n",
      "[8/100][10/14]\n",
      "- D_loss : 1.6692 / G_loss : 0.4497\n",
      "- D(x) : 0.5167 / D(G(z1)) : 0.6352 / D(G(z2)) : 0.6379\n",
      "[8/100][11/14]\n",
      "- D_loss : 1.6748 / G_loss : 0.4496\n",
      "- D(x) : 0.5142 / D(G(z1)) : 0.6356 / D(G(z2)) : 0.6379\n",
      "[8/100][12/14]\n",
      "- D_loss : 1.6716 / G_loss : 0.4497\n",
      "- D(x) : 0.5160 / D(G(z1)) : 0.6357 / D(G(z2)) : 0.6378\n",
      "[8/100][13/14]\n",
      "- D_loss : 1.6667 / G_loss : 0.4497\n",
      "- D(x) : 0.5179 / D(G(z1)) : 0.6352 / D(G(z2)) : 0.6378\n",
      "[9/100][0/14]\n",
      "- D_loss : 1.6708 / G_loss : 0.4495\n",
      "- D(x) : 0.5161 / D(G(z1)) : 0.6354 / D(G(z2)) : 0.6379\n",
      "[9/100][1/14]\n",
      "- D_loss : 1.6690 / G_loss : 0.4497\n",
      "- D(x) : 0.5166 / D(G(z1)) : 0.6351 / D(G(z2)) : 0.6378\n",
      "[9/100][2/14]\n",
      "- D_loss : 1.6722 / G_loss : 0.4499\n",
      "- D(x) : 0.5152 / D(G(z1)) : 0.6353 / D(G(z2)) : 0.6377\n",
      "[9/100][3/14]\n",
      "- D_loss : 1.6716 / G_loss : 0.4503\n",
      "- D(x) : 0.5154 / D(G(z1)) : 0.6353 / D(G(z2)) : 0.6374\n",
      "[9/100][4/14]\n",
      "- D_loss : 1.6679 / G_loss : 0.4511\n",
      "- D(x) : 0.5166 / D(G(z1)) : 0.6347 / D(G(z2)) : 0.6370\n",
      "[9/100][5/14]\n",
      "- D_loss : 1.6681 / G_loss : 0.4513\n",
      "- D(x) : 0.5165 / D(G(z1)) : 0.6348 / D(G(z2)) : 0.6368\n",
      "[9/100][6/14]\n",
      "- D_loss : 1.6665 / G_loss : 0.4525\n",
      "- D(x) : 0.5164 / D(G(z1)) : 0.6341 / D(G(z2)) : 0.6360\n",
      "[9/100][7/14]\n",
      "- D_loss : 1.6640 / G_loss : 0.4527\n",
      "- D(x) : 0.5176 / D(G(z1)) : 0.6340 / D(G(z2)) : 0.6359\n",
      "[9/100][8/14]\n",
      "- D_loss : 1.6629 / G_loss : 0.4532\n",
      "- D(x) : 0.5175 / D(G(z1)) : 0.6335 / D(G(z2)) : 0.6356\n",
      "[9/100][9/14]\n",
      "- D_loss : 1.6615 / G_loss : 0.4538\n",
      "- D(x) : 0.5175 / D(G(z1)) : 0.6330 / D(G(z2)) : 0.6352\n",
      "[9/100][10/14]\n",
      "- D_loss : 1.6610 / G_loss : 0.4544\n",
      "- D(x) : 0.5176 / D(G(z1)) : 0.6329 / D(G(z2)) : 0.6348\n",
      "[9/100][11/14]\n",
      "- D_loss : 1.6592 / G_loss : 0.4554\n",
      "- D(x) : 0.5179 / D(G(z1)) : 0.6324 / D(G(z2)) : 0.6342\n",
      "[9/100][12/14]\n",
      "- D_loss : 1.6619 / G_loss : 0.4560\n",
      "- D(x) : 0.5156 / D(G(z1)) : 0.6319 / D(G(z2)) : 0.6338\n",
      "[9/100][13/14]\n",
      "- D_loss : 1.6553 / G_loss : 0.4567\n",
      "- D(x) : 0.5184 / D(G(z1)) : 0.6314 / D(G(z2)) : 0.6334\n",
      "[10/100][0/14]\n",
      "- D_loss : 1.6565 / G_loss : 0.4574\n",
      "- D(x) : 0.5170 / D(G(z1)) : 0.6308 / D(G(z2)) : 0.6330\n",
      "[10/100][1/14]\n",
      "- D_loss : 1.6566 / G_loss : 0.4573\n",
      "- D(x) : 0.5169 / D(G(z1)) : 0.6308 / D(G(z2)) : 0.6330\n",
      "[10/100][2/14]\n",
      "- D_loss : 1.6543 / G_loss : 0.4562\n",
      "- D(x) : 0.5184 / D(G(z1)) : 0.6310 / D(G(z2)) : 0.6337\n",
      "[10/100][3/14]\n",
      "- D_loss : 1.6594 / G_loss : 0.4552\n",
      "- D(x) : 0.5167 / D(G(z1)) : 0.6317 / D(G(z2)) : 0.6343\n",
      "[10/100][4/14]\n",
      "- D_loss : 1.6578 / G_loss : 0.4541\n",
      "- D(x) : 0.5181 / D(G(z1)) : 0.6321 / D(G(z2)) : 0.6350\n",
      "[10/100][5/14]\n",
      "- D_loss : 1.6643 / G_loss : 0.4525\n",
      "- D(x) : 0.5160 / D(G(z1)) : 0.6330 / D(G(z2)) : 0.6360\n",
      "[10/100][6/14]\n",
      "- D_loss : 1.6614 / G_loss : 0.4514\n",
      "- D(x) : 0.5191 / D(G(z1)) : 0.6341 / D(G(z2)) : 0.6367\n",
      "[10/100][7/14]\n",
      "- D_loss : 1.6679 / G_loss : 0.4505\n",
      "- D(x) : 0.5170 / D(G(z1)) : 0.6350 / D(G(z2)) : 0.6373\n",
      "[10/100][8/14]\n",
      "- D_loss : 1.6678 / G_loss : 0.4502\n",
      "- D(x) : 0.5173 / D(G(z1)) : 0.6352 / D(G(z2)) : 0.6375\n",
      "[10/100][9/14]\n",
      "- D_loss : 1.6684 / G_loss : 0.4501\n",
      "- D(x) : 0.5175 / D(G(z1)) : 0.6356 / D(G(z2)) : 0.6376\n",
      "[10/100][10/14]\n",
      "- D_loss : 1.6694 / G_loss : 0.4497\n",
      "- D(x) : 0.5174 / D(G(z1)) : 0.6358 / D(G(z2)) : 0.6378\n",
      "[10/100][11/14]\n",
      "- D_loss : 1.6692 / G_loss : 0.4502\n",
      "- D(x) : 0.5171 / D(G(z1)) : 0.6356 / D(G(z2)) : 0.6375\n",
      "[10/100][12/14]\n",
      "- D_loss : 1.6709 / G_loss : 0.4507\n",
      "- D(x) : 0.5165 / D(G(z1)) : 0.6358 / D(G(z2)) : 0.6372\n",
      "[10/100][13/14]\n",
      "- D_loss : 1.6726 / G_loss : 0.4509\n",
      "- D(x) : 0.5154 / D(G(z1)) : 0.6357 / D(G(z2)) : 0.6370\n",
      "[11/100][0/14]\n",
      "- D_loss : 1.6657 / G_loss : 0.4518\n",
      "- D(x) : 0.5181 / D(G(z1)) : 0.6350 / D(G(z2)) : 0.6365\n",
      "[11/100][1/14]\n",
      "- D_loss : 1.6576 / G_loss : 0.4522\n",
      "- D(x) : 0.5220 / D(G(z1)) : 0.6348 / D(G(z2)) : 0.6362\n",
      "[11/100][2/14]\n",
      "- D_loss : 1.6650 / G_loss : 0.4525\n",
      "- D(x) : 0.5175 / D(G(z1)) : 0.6343 / D(G(z2)) : 0.6360\n",
      "[11/100][3/14]\n",
      "- D_loss : 1.6646 / G_loss : 0.4523\n",
      "- D(x) : 0.5175 / D(G(z1)) : 0.6342 / D(G(z2)) : 0.6362\n",
      "[11/100][4/14]\n",
      "- D_loss : 1.6713 / G_loss : 0.4518\n",
      "- D(x) : 0.5145 / D(G(z1)) : 0.6345 / D(G(z2)) : 0.6365\n",
      "[11/100][5/14]\n",
      "- D_loss : 1.6665 / G_loss : 0.4513\n",
      "- D(x) : 0.5175 / D(G(z1)) : 0.6348 / D(G(z2)) : 0.6368\n",
      "[11/100][6/14]\n",
      "- D_loss : 1.6654 / G_loss : 0.4512\n",
      "- D(x) : 0.5183 / D(G(z1)) : 0.6350 / D(G(z2)) : 0.6368\n",
      "[11/100][7/14]\n",
      "- D_loss : 1.6666 / G_loss : 0.4510\n",
      "- D(x) : 0.5180 / D(G(z1)) : 0.6352 / D(G(z2)) : 0.6370\n",
      "[11/100][8/14]\n",
      "- D_loss : 1.6673 / G_loss : 0.4511\n",
      "- D(x) : 0.5176 / D(G(z1)) : 0.6352 / D(G(z2)) : 0.6369\n",
      "[11/100][9/14]\n",
      "- D_loss : 1.6689 / G_loss : 0.4509\n",
      "- D(x) : 0.5166 / D(G(z1)) : 0.6351 / D(G(z2)) : 0.6370\n",
      "[11/100][10/14]\n",
      "- D_loss : 1.6653 / G_loss : 0.4509\n",
      "- D(x) : 0.5183 / D(G(z1)) : 0.6349 / D(G(z2)) : 0.6370\n",
      "[11/100][11/14]\n",
      "- D_loss : 1.6636 / G_loss : 0.4507\n",
      "- D(x) : 0.5197 / D(G(z1)) : 0.6353 / D(G(z2)) : 0.6372\n",
      "[11/100][12/14]\n",
      "- D_loss : 1.6686 / G_loss : 0.4506\n",
      "- D(x) : 0.5174 / D(G(z1)) : 0.6356 / D(G(z2)) : 0.6373\n",
      "[11/100][13/14]\n",
      "- D_loss : 1.6662 / G_loss : 0.4507\n",
      "- D(x) : 0.5188 / D(G(z1)) : 0.6357 / D(G(z2)) : 0.6372\n",
      "[12/100][0/14]\n",
      "- D_loss : 1.6663 / G_loss : 0.4510\n",
      "- D(x) : 0.5185 / D(G(z1)) : 0.6354 / D(G(z2)) : 0.6370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/100][1/14]\n",
      "- D_loss : 1.6666 / G_loss : 0.4512\n",
      "- D(x) : 0.5181 / D(G(z1)) : 0.6353 / D(G(z2)) : 0.6368\n",
      "[12/100][2/14]\n",
      "- D_loss : 1.6683 / G_loss : 0.4514\n",
      "- D(x) : 0.5171 / D(G(z1)) : 0.6352 / D(G(z2)) : 0.6368\n",
      "[12/100][3/14]\n",
      "- D_loss : 1.6658 / G_loss : 0.4521\n",
      "- D(x) : 0.5182 / D(G(z1)) : 0.6352 / D(G(z2)) : 0.6363\n",
      "[12/100][4/14]\n",
      "- D_loss : 1.6650 / G_loss : 0.4527\n",
      "- D(x) : 0.5184 / D(G(z1)) : 0.6349 / D(G(z2)) : 0.6359\n",
      "[12/100][5/14]\n",
      "- D_loss : 1.6647 / G_loss : 0.4538\n",
      "- D(x) : 0.5174 / D(G(z1)) : 0.6341 / D(G(z2)) : 0.6352\n",
      "[12/100][6/14]\n",
      "- D_loss : 1.6582 / G_loss : 0.4551\n",
      "- D(x) : 0.5197 / D(G(z1)) : 0.6334 / D(G(z2)) : 0.6344\n",
      "[12/100][7/14]\n",
      "- D_loss : 1.6512 / G_loss : 0.4571\n",
      "- D(x) : 0.5220 / D(G(z1)) : 0.6324 / D(G(z2)) : 0.6331\n",
      "[12/100][8/14]\n",
      "- D_loss : 1.6546 / G_loss : 0.4588\n",
      "- D(x) : 0.5187 / D(G(z1)) : 0.6314 / D(G(z2)) : 0.6320\n",
      "[12/100][9/14]\n",
      "- D_loss : 1.6507 / G_loss : 0.4604\n",
      "- D(x) : 0.5194 / D(G(z1)) : 0.6304 / D(G(z2)) : 0.6310\n",
      "[12/100][10/14]\n",
      "- D_loss : 1.6475 / G_loss : 0.4620\n",
      "- D(x) : 0.5194 / D(G(z1)) : 0.6292 / D(G(z2)) : 0.6300\n",
      "[12/100][11/14]\n",
      "- D_loss : 1.6485 / G_loss : 0.4635\n",
      "- D(x) : 0.5177 / D(G(z1)) : 0.6284 / D(G(z2)) : 0.6291\n",
      "[12/100][12/14]\n",
      "- D_loss : 1.6472 / G_loss : 0.4646\n",
      "- D(x) : 0.5170 / D(G(z1)) : 0.6274 / D(G(z2)) : 0.6284\n",
      "[12/100][13/14]\n",
      "- D_loss : 1.6404 / G_loss : 0.4659\n",
      "- D(x) : 0.5195 / D(G(z1)) : 0.6266 / D(G(z2)) : 0.6276\n",
      "[13/100][0/14]\n",
      "- D_loss : 1.6386 / G_loss : 0.4669\n",
      "- D(x) : 0.5192 / D(G(z1)) : 0.6257 / D(G(z2)) : 0.6269\n",
      "[13/100][1/14]\n",
      "- D_loss : 1.6374 / G_loss : 0.4669\n",
      "- D(x) : 0.5194 / D(G(z1)) : 0.6255 / D(G(z2)) : 0.6269\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train(epoch, learning_G_per_D = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_loss():\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "    plt.plot(G_losses, label=\"G\")\n",
    "    plt.plot(D_losses,label=\"D\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_gen_imgs():\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "    HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_gen_imgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vector = torch.randn(1, latent_size, 1, 1, device = device, requires_grad=True)\n",
    "\n",
    "def Anomaly_loss(Test_Data, G_Data, Lambda=0.1):\n",
    "    _, Test_Data_feature = D(Test_Data)\n",
    "    _, G_Data_feature = D(G_Data)\n",
    "    residual_loss = torch.sum(torch.abs(Test_Data - G_Data))\n",
    "    discrimination_loss = torch.sum(torch.abs(Test_Data_feature - G_Data_feature))\n",
    "    ano_loss = (1-Lambda)*residual_loss + Lambda*discrimination_loss\n",
    "    \n",
    "    return ano_loss\n",
    "\n",
    "z_optimizer = torch.optim.Adam([latent_vector],lr=0.01,betas=(0.5, 0.999))\n",
    "\n",
    "\n",
    "test_data_root = \"../../../OhSeHyeon/source/dataset/test/test_DualPhaseSteel\"\n",
    "test_data_set = dataset.ImageFolder(root = test_data_root,\n",
    "                           transform = transforms.Compose([\n",
    "                                  transforms.Resize(img_size),\n",
    "                                  transforms.CenterCrop(img_size),\n",
    "                                  torchvision.transforms.Grayscale(channel),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5,),(0.5,))\n",
    "                              ]))\n",
    "\n",
    "\n",
    "# 배치로 나누고 셔플하기\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data_set, batch_size = 1,\n",
    "                                              shuffle = False, num_workers = workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Latent Space Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space = []\n",
    "auc=[]\n",
    "\n",
    "def train_latent_space():\n",
    "    \n",
    "    for i,data in enumerate(test_data_loader,0):\n",
    "        test_img = data[0].to(device)\n",
    "        print(\"picture \", i+1)\n",
    "        for step in range(401):\n",
    "\n",
    "            G_Data = G(latent_vector)\n",
    "            ano_loss = Anomaly_loss(test_img, G_Data)\n",
    "\n",
    "            z_optimizer.zero_grad()\n",
    "\n",
    "            # residual loss, dicriminator loss 의 그래디언트를 학습 가능한 weight에 독립적으로 반역하기 위해서\n",
    "            # 한쪽 로스를 업데이트하면 그래디언트가 해제되서 \n",
    "            ano_loss.backward(retain_graph = True)\n",
    "\n",
    "            z_optimizer.step()\n",
    "\n",
    "            if step%200 == 0:\n",
    "\n",
    "                loss   = ano_loss.item()\n",
    "                noises = torch.sum(latent_vector).item()\n",
    "                print(\"[%d]\\t Ano_loss : %.4f  Sum_of_z : %.4f\" %(step,loss,noises))\n",
    "                if step == 400:\n",
    "                    latent_space.append(latent_vector.cpu().data.numpy())\n",
    "                    if loss > 500:\n",
    "                        auc.append(1)\n",
    "                    else :\n",
    "                        auc.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_latent_space()\n",
    "\n",
    "latent_space = np.array(latent_space)\n",
    "latent_space = torch.Tensor(latent_space).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이상 픽셀 수 확인 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_el_not_0(diff_img):\n",
    "    count_el_not_0 = 0\n",
    "    \n",
    "    col_size = diff_img.shape[0]\n",
    "    row_size = diff_img.shape[1]\n",
    "    \n",
    "    #print(col_size, row_size)\n",
    "    \n",
    "    for col in range(col_size):\n",
    "        for row in range(row_size):\n",
    "            if diff_img[col][row] != 0:\n",
    "                count_el_not_0 += 1\n",
    "                \n",
    "    return count_el_not_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similar Z , Ano_Score and Segementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_cnts = []\n",
    "diff_points = []\n",
    "anomaly_imgs = []\n",
    "\n",
    "\n",
    "def compare_imgs(real_img, generated_img, i, reverse=False, threshold=50):\n",
    "    global anomaly_img\n",
    "    \n",
    "    score = Anomaly_loss(real_img, generated_img)\n",
    "    score = round(score.item(), 2)\n",
    "    \n",
    "    real_img = real_img.cpu().data.numpy().reshape(img_size, img_size) * 255\n",
    "    generated_img = generated_img.cpu().data.numpy().reshape(img_size, img_size) * 255\n",
    "    negative = np.zeros_like(real_img)\n",
    "    \n",
    "    if not reverse:\n",
    "        diff_img = real_img - generated_img\n",
    "    else:\n",
    "        diff_img = generated_img - real_img\n",
    "    diff_img[diff_img <= threshold] = 0\n",
    "    # 분율 추출\n",
    "    diff_cnts.append(count_el_not_0(diff_img))\n",
    "    # 분산 추출\n",
    "    diff_points.append(np.where(diff_img > threshold))\n",
    "    \n",
    "    \n",
    "    anomaly_img = np.zeros(shape=(img_size, img_size, 3))\n",
    "    anomaly_img[:, :, 0] = real_img - diff_img\n",
    "    anomaly_img[:, :, 1] = real_img - diff_img\n",
    "    anomaly_img[:, :, 2] = real_img - diff_img\n",
    "    anomaly_img[:, :, 0] = anomaly_img[:,:,0] + diff_img\n",
    "    anomaly_img = anomaly_img.astype(np.uint8)\n",
    "    # anomaly_img 추출\n",
    "    anomaly_imgs.append(anomaly_img)\n",
    "    \n",
    "    fig, plots = plt.subplots(1, 4)\n",
    "    if auc[i] == 0:\n",
    "        fig.suptitle(f'Normal - (anomaly score: {score:.4})')\n",
    "    else :\n",
    "        fig.suptitle(f'Anomaly - (anomaly score: {score:.4})')\n",
    "    \n",
    "    fig.set_figwidth(9)\n",
    "    fig.set_tight_layout(True)\n",
    "    plots = plots.reshape(-1)\n",
    "    plots[0].imshow(real_img, cmap='gray', label = \"real\")\n",
    "    plots[1].imshow(generated_img, cmap='gray')\n",
    "    plots[2].imshow(diff_img, cmap='gray')\n",
    "    plots[3].imshow(anomaly_img)\n",
    "    \n",
    "    plots[0].set_title('real')\n",
    "    plots[1].set_title('generated')\n",
    "    plots[2].set_title('difference')\n",
    "    plots[3].set_title('Anomaly Detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,data in enumerate(test_data_loader,0):\n",
    "    test_img = data[0].to(device)\n",
    "\n",
    "    #for i in range(len(latent_space)):\n",
    "    update_z = latent_space[i]\n",
    "    R_img = test_img\n",
    "    G_img = G(update_z).to(device)\n",
    "    \n",
    "    if i in [9]:\n",
    "        compare_imgs(R_img, G_img,i,reverse = True, threshold = 50)\n",
    "    else:\n",
    "        compare_imgs(R_img, G_img,i,reverse = False, threshold = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분율 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_cnts = np.array(diff_cnts)\n",
    "\n",
    "diff_fraction = diff_cnts / img_size ** 2\n",
    "\n",
    "print(diff_fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분산 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from extended_int import int_inf\n",
    "\n",
    "corr_coeffis = []\n",
    "corr_p_vals = []\n",
    "\n",
    "def cal_corr_coeffis():\n",
    "    for idx in range(len(test_data_loader)):\n",
    "        x_points = diff_points[idx][0]\n",
    "        y_points = diff_points[idx][1]\n",
    "        \n",
    "        \n",
    "        if len(x_points) > 0:\n",
    "            corr_coeffi, corr_p_val = stats.pearsonr(x_points, y_points)\n",
    "        else:\n",
    "            corr_coeffi, corr_p_val = -int_inf, -int_inf\n",
    "        \n",
    "        corr_coeffis.append(corr_coeffi)\n",
    "        corr_p_vals.append(corr_p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_corr_coeffis()\n",
    "\n",
    "print(corr_coeffis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장 및 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = \"./pretrained/pretrained.pth\"\n",
    "\n",
    "def save_pretrained():\n",
    "    pretrained = {\n",
    "        \"D\" : D.state_dict(),\n",
    "        \"G\" : G.state_dict(),\n",
    "        #\"latent_space\" : latent_space.state_dict(), # nn.model만 가지는 기능\n",
    "    }\n",
    "\n",
    "    if not os.path.isdir(\"pretrained\"):\n",
    "        os.mkdir(\"pretrained\")\n",
    "    torch.save(pretrained, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_D = Discriminator().to(device)\n",
    "pretrained_G = Generator().to(device)\n",
    "#pretrained_latent_space = [] # 다시 학습해야 함\n",
    "\n",
    "def load_pretrained():\n",
    "    global pretrained_D\n",
    "    global pretrained_G\n",
    "    #global pretrained_latent_space\n",
    "    \n",
    "    assert os.path.isdir(\"pretrained\"), \"Error : no pretrained dir found!\"\n",
    "    \n",
    "    pretrained = torch.load(save_file)\n",
    "    \n",
    "    pretrained_D.load_state_dict(pretrained[\"D\"])\n",
    "    pretrained_G.load_state_dict(pretrained[\"G\"])\n",
    "    #pretrained_latent_space.load_state_dict(pretrained[\"latent_space\"])\n",
    "    \n",
    "    #print(\"pretrained_D :\", pretrained_D)\n",
    "    #print(\"pretrained_G :\", pretrained_G)\n",
    "    #print(\"pretrained_latent_space :\", pretrained_latent_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Anomaly_loss(Test_Data, G_Data, Lambda=0.1):\n",
    "    \n",
    "    _, Test_Data_feature = pretrained_D(Test_Data)\n",
    "    _, G_Data_feature = pretrained_D(G_Data)\n",
    "    residual_loss = torch.sum(torch.abs(Test_Data - G_Data))\n",
    "    discrimination_loss = torch.sum(torch.abs(Test_Data_feature - G_Data_feature))\n",
    "    ano_loss = (1-Lambda)*residual_loss + Lambda*discrimination_loss\n",
    "    \n",
    "    return ano_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train latent_space\n",
    "\n",
    "latent_space = []\n",
    "auc = []\n",
    "\n",
    "def train_latent_space():\n",
    "    global latent_space\n",
    "    global auc\n",
    "    \n",
    "    for i,data in enumerate(test_data_loader,0):\n",
    "        test_img = data[0].to(device)\n",
    "        print(\"picture \", i+1)\n",
    "        for step in range(401):\n",
    "\n",
    "            G_Data   = pretrained_G(latent_vector)\n",
    "            ano_loss = Anomaly_loss(test_img, G_Data)\n",
    "\n",
    "            z_optimizer.zero_grad()\n",
    "\n",
    "            # residual loss, dicriminator loss 의 그래디언트를 학습 가능한 weight에 독립적으로 반역하기 위해서\n",
    "            # 한쪽 로스를 업데이트하면 그래디언트가 해제되서 \n",
    "            ano_loss.backward(retain_graph = True)\n",
    "\n",
    "            z_optimizer.step()\n",
    "\n",
    "            if step%200 == 0:\n",
    "\n",
    "                loss   = ano_loss.item()\n",
    "                noises = torch.sum(latent_vector).item()\n",
    "                print(\"[%d]\\t Ano_loss : %.4f  Sum_of_z : %.4f\" %(step,loss,noises))\n",
    "                if step==400:\n",
    "                    latent_space.append(latent_vector.cpu().data.numpy())\n",
    "                    if loss>500:\n",
    "                        auc.append(1)\n",
    "                    else :\n",
    "                        auc.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_latent_space()\n",
    "\n",
    "latent_space = np.array(latent_space)\n",
    "latent_space = torch.Tensor(latent_space).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    for i,data in enumerate(test_data_loader,0):\n",
    "        test_img = data[0].to(device)\n",
    "\n",
    "        #for i in range(len(latent_space)):\n",
    "        update_z = latent_space[i]\n",
    "        R_img = test_img\n",
    "        G_img = pretrained_G(update_z).to(device)\n",
    "\n",
    "        if i in [9]:\n",
    "            compare_imgs(R_img, G_img,i,reverse = True, threshold = 50)\n",
    "        else:\n",
    "            compare_imgs(R_img, G_img,i,reverse = False, threshold = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_cnts = []\n",
    "diff_points = []\n",
    "anomaly_imgs = []\n",
    "\n",
    "corr_coeffis = []\n",
    "corr_p_vals = []\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_cnts = np.array(diff_cnts)\n",
    "\n",
    "diff_fraction = diff_cnts / img_size ** 2\n",
    "\n",
    "print(diff_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_corr_coeffis()\n",
    "\n",
    "print(corr_coeffis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# anomaly detection 이미지 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 저장 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def save_imgs(folder, imgs):\n",
    "    if not os.path.isdir(\"anomaly_imgs\"):\n",
    "        os.mkdir(\"anomaly_imgs\")\n",
    "    \n",
    "    for i in range(len(imgs)):\n",
    "        cv2.imwrite('%s/%d.png' %(folder,i), imgs[i]) #이미지 저장할 경로 설정을 여기서 한다.\n",
    "    print(\"image saving complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_imgs(\"./anomaly_imgs\", anomaly_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 티타늄(Ti64) 상대 밀도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ti64_density = 4.43\n",
    "\n",
    "Ti64_rel_densitys = np.array([])\n",
    "\n",
    "Ti64_rel_densitys = diff_fraction * Ti64_density\n",
    "\n",
    "print(Ti64_rel_densitys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
