{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANomaly\n",
    "- 2020.08.17 : gen 10 / lr 1e-2\n",
    "\n",
    "# 개발일지\n",
    "- 2020.08.15 : 분율 추출 구현 / 이상치 상관계수 추출 구현 / 모델 save, load 구현\n",
    "- 2020.08.16 : anomaly detect 이미지 저장 구현 / 티타늄(Ti64) 상대 밀도 계산 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# Graph & Animation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 100  # z벡터의 잠재공간(latent space)의 크기\n",
    "workers = 4    # 0일때, 약 20% 사용 4일 경우 메모리 100%\n",
    "img_size = 64\n",
    "channel = 1\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dataset : 1020\n",
      "device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 이미지 경로, 이미지들 리사이즈 및 텐서형태로 만들기\n",
    "#data_root = \"../../dataset/train\"\n",
    "Ti64_aug_data_root = \"../../dataset/aug_train/aug_Ti64\"\n",
    "\n",
    "data_set = dataset.ImageFolder(root = Ti64_aug_data_root, # data_root,\n",
    "                           transform = transforms.Compose([\n",
    "                                  #transforms.Resize(img_size),\n",
    "                                  transforms.CenterCrop(img_size),\n",
    "                                  torchvision.transforms.Grayscale(channel),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5,),(0.5,))\n",
    "                              ]))\n",
    "\n",
    "print(\"size of dataset :\", len(data_set))\n",
    "\n",
    "# 배치로 나누고 셔플하기\n",
    "data_loader = torch.utils.data.DataLoader(data_set, batch_size = batch_size,\n",
    "                                         shuffle = True, num_workers = workers, drop_last=True)\n",
    "\n",
    "# Device setting (GPU or CPU)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device :\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GANomaly : Generative Adversarial Networks Model using Decoder with AutoEncoder\n",
    "\n",
    "# === Decoder 모델 ===\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder,self).__init__()\n",
    "        \n",
    "        # Batch Normalization 유무에 따른 G_block 정의\n",
    "        def DC_conv_block(in_features, out_features):\n",
    "            block = [\n",
    "                    nn.Conv2d(in_features, out_features, 3, 1, 1, bias=False),\n",
    "                    nn.BatchNorm2d(out_features),\n",
    "                    nn.ELU()\n",
    "            ]\n",
    "            return block\n",
    "        \n",
    "        def DC_deconv_block(in_features, out_features, FIRST=True):\n",
    "            if FIRST:\n",
    "                block = [\n",
    "                    nn.ConvTranspose2d(in_features, out_features, 4, 1, 0, bias=False),\n",
    "                    nn.BatchNorm2d(out_features),\n",
    "                    nn.ELU()\n",
    "                ]\n",
    "            else:\n",
    "                block = [\n",
    "                    nn.ConvTranspose2d(in_features, out_features, 4, 2, 1, bias=False),\n",
    "                    nn.BatchNorm2d(out_features),\n",
    "                    nn.ELU()\n",
    "                ]\n",
    "            return block\n",
    "        \n",
    "        \n",
    "        # ======================= 픽셀 분포 생성 layer ======================= \n",
    "        self.DC_gen_distribution = nn.Sequential(\n",
    "            # ------ input is latent_size 100 ------ \n",
    "            *DC_deconv_block(latent_size, img_size*8, FIRST=True),\n",
    "            # ------ state size is 512x4x4 ------ \n",
    "            *DC_conv_block(img_size*8, img_size*8),\n",
    "            # ------ state size is 512x4x4 ------   \n",
    "            *DC_deconv_block(img_size*8, img_size*4, FIRST=False),\n",
    "            # ------ state size is 256x8x8 ------ \n",
    "            *DC_conv_block(img_size*4, img_size*4),\n",
    "            # ------ state size is 256x8x8 ------ \n",
    "            *DC_deconv_block(img_size*4, img_size*2, FIRST=False),\n",
    "            # ------ state size is 128x16x16 ------ \n",
    "            *DC_conv_block(img_size*2, img_size*2),\n",
    "            # ------ state size is 128x16x16 ------ \n",
    "            *DC_deconv_block(img_size*2, img_size, FIRST=False),\n",
    "        )\n",
    "        \n",
    "        # =================== 가짜 이미지 생성 layer =================== \n",
    "        self.DC_gen_fake_img = nn.Sequential(\n",
    "            # ------ state size is 64x32x32 ------ \n",
    "            nn.ConvTranspose2d(img_size, 1, 4, 2, 1, bias=False),\n",
    "            nn.Tanh() # 픽셀값의 범위 : -1 ~ 1로 두기 위해서\n",
    "            # ------ state size is 1x64x64 ------ \n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        distribution = self.DC_gen_distribution(input)\n",
    "        fake_img = self.DC_gen_fake_img(distribution)\n",
    "        \n",
    "        return fake_img\n",
    "\n",
    "\n",
    "# === Discriminator 모델 ===\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Batch Normalization 유무에 따른 D_block 정의\n",
    "        def D_block(in_features, out_features, MP=True):\n",
    "            if MP:\n",
    "                block = [\n",
    "                    nn.Conv2d(in_features, out_features, 3, 1, 1, bias=False),\n",
    "                    nn.BatchNorm2d(out_features),\n",
    "                    nn.ELU()\n",
    "                ]\n",
    "            else:\n",
    "                block = [\n",
    "                    nn.Conv2d(in_features, out_features, 3, 1, 1, bias=False),\n",
    "                    nn.BatchNorm2d(out_features),\n",
    "                    nn.ELU(),\n",
    "                    nn.MaxPool2d(2)\n",
    "                ]\n",
    "            return block\n",
    "        \n",
    "        # ============== Feature 추출 layer ==============\n",
    "        self.D_extract_feature = nn.Sequential(\n",
    "            # ------ input is 1 x 64 x 64 ------ \n",
    "            *D_block(channel, img_size, MP=False),\n",
    "            # ------ input is 64 x 64 x 64 ------ \n",
    "            *D_block(img_size, img_size, MP=True),\n",
    "            # ------ state is 64 x 32 x 32 ------ \n",
    "            *D_block(img_size, img_size*2, MP=False),\n",
    "            # ------ state is 128 x 32 x 32 ------ \n",
    "            *D_block(img_size*2, img_size*2, MP=True),\n",
    "            # ------ state is 128 x 16 x 16 ------ \n",
    "            *D_block(img_size*2, img_size*4, MP=False),\n",
    "            # ------ state is 256 x 16 x 16 ------ \n",
    "            *D_block(img_size*4, img_size*4, MP=True),\n",
    "            # ------ state is 256 x 8 x 8 ------ \n",
    "            *D_block(img_size*4, img_size*8, MP=False),\n",
    "            # ------ state is 512 x 8 x 8 ------ \n",
    "            *D_block(img_size*8, img_size*8, MP=True),\n",
    "        )\n",
    "        \n",
    "        # ===================== 이진 분류 layer =====================\n",
    "        self.D_classification = nn.Sequential(        \n",
    "            # ------- state size 512x4x4 ------- \n",
    "            nn.Conv2d(img_size*8, channel, 4, 1, 0, bias=False),\n",
    "            #nn.Linear(fms*8*4*4, 1, bias=False),\n",
    "            nn.Sigmoid()        \n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        feature = self.D_extract_feature(input)\n",
    "        classification = self.D_classification(feature)\n",
    "        \n",
    "        return classification, feature \n",
    "\n",
    "\n",
    "# === Encoder Model ===\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        def EC_block(in_features, out_features, MP=True):\n",
    "            if MP:\n",
    "                block = [\n",
    "                    nn.Conv2d(in_features, out_features, 3, 1, 1, bias=False),\n",
    "                    nn.BatchNorm2d(out_features),\n",
    "                    nn.ELU()\n",
    "                ]\n",
    "            else:\n",
    "                block = [\n",
    "                    nn.Conv2d(in_features, out_features, 3, 1, 1, bias=False),\n",
    "                    nn.BatchNorm2d(out_features),\n",
    "                    nn.ELU(),\n",
    "                    nn.MaxPool2d(2)\n",
    "                ]\n",
    "            return block\n",
    "        \n",
    "        # ============== Feature 추출 ==============\n",
    "        self.EC_extract_feature = nn.Sequential(\n",
    "            # ------ input is 1 x 64 x 64 ------ \n",
    "            *EC_block(channel, img_size, MP=False),\n",
    "            # ------ input is 64 x 64 x 64 ------ \n",
    "            *EC_block(img_size, img_size, MP=True),\n",
    "            # ------ state is 64 x 32 x 32 ------ \n",
    "            *EC_block(img_size, img_size*2, MP=False),\n",
    "            # ------ state is 128 x 32 x 32 ------ \n",
    "            *EC_block(img_size*2, img_size*2, MP=True),\n",
    "            # ------ state is 128 x 16 x 16 ------ \n",
    "            *EC_block(img_size*2, img_size*4, MP=False),\n",
    "            # ------ state is 256 x 16 x 16 ------ \n",
    "            *EC_block(img_size*4, img_size*4, MP=True),\n",
    "            # ------ state is 256 x 8 x 8 ------ \n",
    "            *EC_block(img_size*4, img_size*8, MP=False),\n",
    "            # ------ state is 512 x 8 x 8 ------ \n",
    "            *EC_block(img_size*8, img_size*8, MP=True),\n",
    "        )\n",
    "        \n",
    "        # =============== Encoder Training layer ===============\n",
    "        self.EC_validate = nn.Sequential(\n",
    "            # -------state is 512 x 4 x 4-------\n",
    "            nn.Conv2d(img_size*8, latent_size, 4, 1, 0, bias=False),\n",
    "            nn.Tanh()\n",
    "            # -------state is 100 x 97 x 97-------\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        feature = self.EC_extract_feature(input)\n",
    "        validity = self.EC_validate(feature)\n",
    "        \n",
    "        return validity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss & Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DC and D 무게 초기화, classname 에 찾는 name가 없다면 -1 ,\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "# D,DC,EC 네트워크 모델 객체 선언\n",
    "D = Discriminator().to(device)\n",
    "DC = Decoder().to(device)\n",
    "EC = Encoder().to(device)\n",
    "\n",
    "# weight initialize/ nn.Module 클래스 안에 apply 함수가 정의되 있음, 각 함수들에 다 적용 하게한다\n",
    "D.apply(weights_init)\n",
    "DC.apply(weights_init)\n",
    "EC.apply(weights_init)\n",
    "\n",
    "# Binary cross entropy loss and optimizer\n",
    "DCGAN_criterion = nn.BCELoss()\n",
    "AE_criterion = nn.MSELoss()\n",
    "\n",
    "# latent vector에 배치 사이즈 64를 적용\n",
    "# 학습한 DC로 새로운 것 만들어서 결과 확인 할때 사용\n",
    "noise_z = torch.randn(img_size, latent_size, 1, 1, device = device)\n",
    "\n",
    "# D와 DC에 대해 두가지 최적화 설정\n",
    "D_optimizer = torch.optim.Adam(D.parameters(), lr = learning_rate, betas=(0.5,0.999))\n",
    "DC_optimizer = torch.optim.Adam(DC.parameters(), lr = learning_rate, betas=(0.5,0.999))\n",
    "EC_optimizer = torch.optim.Adam(EC.parameters(), lr = learning_rate, betas=(0.5,0.999))\n",
    "\n",
    "#print(D)\n",
    "#print(DC)\n",
    "#print(EC)\n",
    "\n",
    "def reset_grad():\n",
    "    D_optimizer.zero_grad()\n",
    "    DC_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "DC_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "def train_DCGAN(epoch, learning_DC_per_D = 4):\n",
    "    global epochs\n",
    "    global iters\n",
    "    \n",
    "    # 인덱스 0부터 세기 시작\n",
    "    # data[0].size():64x1x64x64(image) / data[1].size():64(label)\n",
    "    for i,data in enumerate(data_loader,0):\n",
    "        \n",
    "        # Train D\n",
    "        real_img = data[0].to(device) # image size: 64x1x64x64(batch, channel, width, height)\n",
    "        b_size = real_img.size(0) # b_size = 64\n",
    "        real_labels = torch.ones(b_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(b_size, 1).to(device)\n",
    "        \n",
    "        # (--------------------------real-----------------------------)\n",
    "        real_classification, _ = D(real_img) # output = D(x)\n",
    "        real_loss = DCGAN_criterion(real_classification, real_labels) # D(x)=1일 때의 loss\n",
    "        real_score = real_classification\n",
    "        D_x = real_score.mean().item() \n",
    "            \n",
    "        # (--------------------------fake-----------------------------)\n",
    "        z = torch.randn(b_size, latent_size, 1, 1).to(device) # z size :64x100x1x1\n",
    "        fake_img = DC(z)\n",
    "        fake_classification, _ = D(fake_img) # output = D(DC(z))\n",
    "        fake_loss = DCGAN_criterion(fake_classification, fake_labels) # D(DC(z))=0일 때의 loss\n",
    "        fake_score = fake_classification\n",
    "        D_DC_z1 = fake_score.mean().item()\n",
    "\n",
    "        # (------------------Backprop and optimize---------------------)\n",
    "        D_loss = real_loss + fake_loss\n",
    "        reset_grad()\n",
    "        D_loss.backward()\n",
    "        D_optimizer.step() # D(x)=1, D(DC(z))=0이어야 D가 최적\n",
    "\n",
    "        \n",
    "        # Train DC\n",
    "        #z = torch.randn(b_size,latent_size,1,1,device=device) # z size :64x100x1x1\n",
    "        for k in range(learning_DC_per_D):\n",
    "            fake_img = DC(z)\n",
    "            fake_classification,_ = D(fake_img)  # output : D(DC(z))\n",
    "            D_DC_z2 = fake_classification.mean().item()\n",
    "            DC_loss = DCGAN_criterion(fake_classification, real_labels) # D(DC(z))=1일 때의 loss=log(D(DC(z)))\n",
    "\n",
    "            # (------------------Backprop and optimize---------------------)\n",
    "            reset_grad()\n",
    "            DC_loss.backward()\n",
    "            DC_optimizer.step() # D(DC(z))=1 이어야 DC가 최적\n",
    "            # ==> D(DC(z))의 값이 0.5로 수렴해야 한다.\n",
    "        \n",
    "        \n",
    "        # print\n",
    "        print('[%d/%d][%d/%d]\\n- D_loss : %.4f / DC_loss : %.4f\\n- D(x):%.4f / D(DC(z1)) : %.4f / D(DC(z2)) : %.4f' \n",
    "                   %(epoch+1, epochs, i, len(data_loader),D_loss.item(),\n",
    "                     DC_loss.item(),D_x,D_DC_z1,D_DC_z2))\n",
    "        \n",
    "        # Save Losses for plotting later\n",
    "        DC_losses.append(DC_loss.item())\n",
    "        D_losses.append(D_loss.item())\n",
    "        \n",
    "        #Check how the generator is doing by saving G's output on noise_z\n",
    "        if (iters % 500 == 0) or ((epoch == epochs-1) and (i == len(data_loader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = DC(noise_z).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "            \n",
    "        iters += 1\n",
    "        \n",
    "#torch.save(E.state_dict(), 'E.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piai/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64, 1, 1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100][0/15]\n",
      "- D_loss : 1.3910 / DC_loss : 0.3009\n",
      "- D(x):0.4948 / D(DC(z1)) : 0.4970 / D(DC(z2)) : 0.7401\n",
      "[1/100][1/15]\n",
      "- D_loss : 2.1665 / DC_loss : 0.6955\n",
      "- D(x):0.4622 / D(DC(z1)) : 0.7416 / D(DC(z2)) : 0.4994\n",
      "[1/100][2/15]\n",
      "- D_loss : 1.6484 / DC_loss : 0.5869\n",
      "- D(x):0.3735 / D(DC(z1)) : 0.4787 / D(DC(z2)) : 0.5561\n",
      "[1/100][3/15]\n",
      "- D_loss : 1.4300 / DC_loss : 0.5334\n",
      "- D(x):0.5384 / D(DC(z1)) : 0.5553 / D(DC(z2)) : 0.5866\n",
      "[1/100][4/15]\n",
      "- D_loss : 1.6405 / DC_loss : 0.8121\n",
      "- D(x):0.4853 / D(DC(z1)) : 0.5999 / D(DC(z2)) : 0.4440\n",
      "[1/100][5/15]\n",
      "- D_loss : 1.4426 / DC_loss : 0.6288\n",
      "- D(x):0.4261 / D(DC(z1)) : 0.4445 / D(DC(z2)) : 0.5332\n",
      "[1/100][6/15]\n",
      "- D_loss : 1.4832 / DC_loss : 0.6899\n",
      "- D(x):0.4867 / D(DC(z1)) : 0.5338 / D(DC(z2)) : 0.5016\n",
      "[1/100][7/15]\n",
      "- D_loss : 1.3925 / DC_loss : 0.6896\n",
      "- D(x):0.4992 / D(DC(z1)) : 0.5021 / D(DC(z2)) : 0.5018\n",
      "[1/100][8/15]\n",
      "- D_loss : 1.4060 / DC_loss : 0.7259\n",
      "- D(x):0.4919 / D(DC(z1)) : 0.5016 / D(DC(z2)) : 0.4842\n",
      "[1/100][9/15]\n",
      "- D_loss : 1.3992 / DC_loss : 0.6667\n",
      "- D(x):0.4769 / D(DC(z1)) : 0.4821 / D(DC(z2)) : 0.5134\n",
      "[1/100][10/15]\n",
      "- D_loss : 1.3951 / DC_loss : 0.6476\n",
      "- D(x):0.5075 / D(DC(z1)) : 0.5117 / D(DC(z2)) : 0.5233\n",
      "[1/100][11/15]\n",
      "- D_loss : 1.3950 / DC_loss : 0.6684\n",
      "- D(x):0.5180 / D(DC(z1)) : 0.5215 / D(DC(z2)) : 0.5126\n",
      "[1/100][12/15]\n",
      "- D_loss : 1.3886 / DC_loss : 0.6887\n",
      "- D(x):0.5091 / D(DC(z1)) : 0.5099 / D(DC(z2)) : 0.5023\n",
      "[1/100][13/15]\n",
      "- D_loss : 1.3905 / DC_loss : 0.6983\n",
      "- D(x):0.4982 / D(DC(z1)) : 0.5002 / D(DC(z2)) : 0.4974\n",
      "[1/100][14/15]\n",
      "- D_loss : 1.3850 / DC_loss : 0.6820\n",
      "- D(x):0.4967 / D(DC(z1)) : 0.4959 / D(DC(z2)) : 0.5057\n",
      "[2/100][0/15]\n",
      "- D_loss : 1.3856 / DC_loss : 0.6888\n",
      "- D(x):0.5040 / D(DC(z1)) : 0.5034 / D(DC(z2)) : 0.5022\n",
      "[2/100][1/15]\n",
      "- D_loss : 1.3863 / DC_loss : 0.7174\n",
      "- D(x):0.5003 / D(DC(z1)) : 0.5003 / D(DC(z2)) : 0.4880\n",
      "[2/100][2/15]\n",
      "- D_loss : 1.3861 / DC_loss : 0.6658\n",
      "- D(x):0.4871 / D(DC(z1)) : 0.4866 / D(DC(z2)) : 0.5139\n",
      "[2/100][3/15]\n",
      "- D_loss : 1.3886 / DC_loss : 0.6725\n",
      "- D(x):0.5109 / D(DC(z1)) : 0.5118 / D(DC(z2)) : 0.5104\n",
      "[2/100][4/15]\n",
      "- D_loss : 1.3909 / DC_loss : 0.7076\n",
      "- D(x):0.5061 / D(DC(z1)) : 0.5082 / D(DC(z2)) : 0.4928\n",
      "[2/100][5/15]\n",
      "- D_loss : 1.3901 / DC_loss : 0.7083\n",
      "- D(x):0.4886 / D(DC(z1)) : 0.4902 / D(DC(z2)) : 0.4925\n",
      "[2/100][6/15]\n",
      "- D_loss : 1.3935 / DC_loss : 0.6860\n",
      "- D(x):0.4878 / D(DC(z1)) : 0.4911 / D(DC(z2)) : 0.5036\n",
      "[2/100][7/15]\n",
      "- D_loss : 1.3925 / DC_loss : 0.6929\n",
      "- D(x):0.4993 / D(DC(z1)) : 0.5024 / D(DC(z2)) : 0.5001\n",
      "[2/100][8/15]\n",
      "- D_loss : 1.3893 / DC_loss : 0.6946\n",
      "- D(x):0.4976 / D(DC(z1)) : 0.4991 / D(DC(z2)) : 0.4993\n",
      "[2/100][9/15]\n",
      "- D_loss : 1.3901 / DC_loss : 0.6895\n",
      "- D(x):0.4971 / D(DC(z1)) : 0.4990 / D(DC(z2)) : 0.5018\n",
      "[2/100][10/15]\n",
      "- D_loss : 1.3884 / DC_loss : 0.6909\n",
      "- D(x):0.5005 / D(DC(z1)) : 0.5015 / D(DC(z2)) : 0.5012\n",
      "[2/100][11/15]\n",
      "- D_loss : 1.3893 / DC_loss : 0.6836\n",
      "- D(x):0.4996 / D(DC(z1)) : 0.5011 / D(DC(z2)) : 0.5048\n",
      "[2/100][12/15]\n",
      "- D_loss : 1.3877 / DC_loss : 0.6902\n",
      "- D(x):0.5037 / D(DC(z1)) : 0.5044 / D(DC(z2)) : 0.5015\n",
      "[2/100][13/15]\n",
      "- D_loss : 1.3874 / DC_loss : 0.6967\n",
      "- D(x):0.5007 / D(DC(z1)) : 0.5012 / D(DC(z2)) : 0.4982\n",
      "[2/100][14/15]\n",
      "- D_loss : 1.3876 / DC_loss : 0.6942\n",
      "- D(x):0.4974 / D(DC(z1)) : 0.4980 / D(DC(z2)) : 0.4995\n",
      "[3/100][0/15]\n",
      "- D_loss : 1.3873 / DC_loss : 0.6887\n",
      "- D(x):0.4988 / D(DC(z1)) : 0.4993 / D(DC(z2)) : 0.5022\n",
      "[3/100][1/15]\n",
      "- D_loss : 1.3877 / DC_loss : 0.6918\n",
      "- D(x):0.5015 / D(DC(z1)) : 0.5022 / D(DC(z2)) : 0.5007\n",
      "[3/100][2/15]\n",
      "- D_loss : 1.3868 / DC_loss : 0.6883\n",
      "- D(x):0.4999 / D(DC(z1)) : 0.5002 / D(DC(z2)) : 0.5025\n",
      "[3/100][3/15]\n",
      "- D_loss : 1.3891 / DC_loss : 0.6972\n",
      "- D(x):0.5006 / D(DC(z1)) : 0.5020 / D(DC(z2)) : 0.4980\n",
      "[3/100][4/15]\n",
      "- D_loss : 1.3866 / DC_loss : 0.6808\n",
      "- D(x):0.4970 / D(DC(z1)) : 0.4971 / D(DC(z2)) : 0.5062\n",
      "[3/100][5/15]\n",
      "- D_loss : 1.3946 / DC_loss : 0.6877\n",
      "- D(x):0.5019 / D(DC(z1)) : 0.5060 / D(DC(z2)) : 0.5028\n",
      "[3/100][6/15]\n",
      "- D_loss : 1.3870 / DC_loss : 0.6710\n",
      "- D(x):0.5003 / D(DC(z1)) : 0.5007 / D(DC(z2)) : 0.5112\n",
      "[3/100][7/15]\n",
      "- D_loss : 1.4041 / DC_loss : 0.7369\n",
      "- D(x):0.4996 / D(DC(z1)) : 0.5084 / D(DC(z2)) : 0.4786\n",
      "[3/100][8/15]\n",
      "- D_loss : 1.3884 / DC_loss : 0.6438\n",
      "- D(x):0.4742 / D(DC(z1)) : 0.4738 / D(DC(z2)) : 0.5254\n",
      "[3/100][9/15]\n",
      "- D_loss : 1.3822 / DC_loss : 0.6610\n",
      "- D(x):0.5163 / D(DC(z1)) : 0.5136 / D(DC(z2)) : 0.5163\n",
      "[3/100][10/15]\n",
      "- D_loss : 1.3920 / DC_loss : 0.7182\n",
      "- D(x):0.5100 / D(DC(z1)) : 0.5125 / D(DC(z2)) : 0.4877\n",
      "[3/100][11/15]\n",
      "- D_loss : 1.3863 / DC_loss : 0.6855\n",
      "- D(x):0.4867 / D(DC(z1)) : 0.4863 / D(DC(z2)) : 0.5038\n",
      "[3/100][12/15]\n",
      "- D_loss : 1.3893 / DC_loss : 0.6771\n",
      "- D(x):0.5008 / D(DC(z1)) : 0.5023 / D(DC(z2)) : 0.5081\n",
      "[3/100][13/15]\n",
      "- D_loss : 1.3933 / DC_loss : 0.7076\n",
      "- D(x):0.5033 / D(DC(z1)) : 0.5066 / D(DC(z2)) : 0.4929\n",
      "[3/100][14/15]\n",
      "- D_loss : 1.3970 / DC_loss : 0.6896\n",
      "- D(x):0.4868 / D(DC(z1)) : 0.4918 / D(DC(z2)) : 0.5018\n",
      "[4/100][0/15]\n",
      "- D_loss : 1.3883 / DC_loss : 0.6891\n",
      "- D(x):0.4997 / D(DC(z1)) : 0.5006 / D(DC(z2)) : 0.5020\n",
      "[4/100][1/15]\n",
      "- D_loss : 1.3877 / DC_loss : 0.6949\n",
      "- D(x):0.5009 / D(DC(z1)) : 0.5016 / D(DC(z2)) : 0.4992\n",
      "[4/100][2/15]\n",
      "- D_loss : 1.3868 / DC_loss : 0.6909\n",
      "- D(x):0.4984 / D(DC(z1)) : 0.4986 / D(DC(z2)) : 0.5011\n",
      "[4/100][3/15]\n",
      "- D_loss : 1.3851 / DC_loss : 0.6785\n",
      "- D(x):0.5009 / D(DC(z1)) : 0.5003 / D(DC(z2)) : 0.5074\n",
      "[4/100][4/15]\n",
      "- D_loss : 1.3881 / DC_loss : 0.7022\n",
      "- D(x):0.5051 / D(DC(z1)) : 0.5059 / D(DC(z2)) : 0.4955\n",
      "[4/100][5/15]\n",
      "- D_loss : 1.3859 / DC_loss : 0.6701\n",
      "- D(x):0.4933 / D(DC(z1)) : 0.4930 / D(DC(z2)) : 0.5116\n",
      "[4/100][6/15]\n",
      "- D_loss : 1.3862 / DC_loss : 0.7022\n",
      "- D(x):0.5118 / D(DC(z1)) : 0.5115 / D(DC(z2)) : 0.4955\n",
      "[4/100][7/15]\n",
      "- D_loss : 1.3824 / DC_loss : 0.6947\n",
      "- D(x):0.4954 / D(DC(z1)) : 0.4934 / D(DC(z2)) : 0.4993\n",
      "[4/100][8/15]\n",
      "- D_loss : 1.3816 / DC_loss : 0.6814\n",
      "- D(x):0.4990 / D(DC(z1)) : 0.4966 / D(DC(z2)) : 0.5059\n",
      "[4/100][9/15]\n",
      "- D_loss : 1.3790 / DC_loss : 0.6743\n",
      "- D(x):0.5047 / D(DC(z1)) : 0.5010 / D(DC(z2)) : 0.5095\n",
      "[4/100][10/15]\n",
      "- D_loss : 1.3795 / DC_loss : 0.7222\n",
      "- D(x):0.5075 / D(DC(z1)) : 0.5039 / D(DC(z2)) : 0.4859\n",
      "[4/100][11/15]\n",
      "- D_loss : 1.3857 / DC_loss : 0.6371\n",
      "- D(x):0.4834 / D(DC(z1)) : 0.4821 / D(DC(z2)) : 0.5289\n",
      "[4/100][12/15]\n",
      "- D_loss : 1.4001 / DC_loss : 0.6728\n",
      "- D(x):0.5253 / D(DC(z1)) : 0.5305 / D(DC(z2)) : 0.5103\n",
      "[4/100][13/15]\n",
      "- D_loss : 1.3954 / DC_loss : 0.7746\n",
      "- D(x):0.5044 / D(DC(z1)) : 0.5089 / D(DC(z2)) : 0.4609\n",
      "[4/100][14/15]\n",
      "- D_loss : 1.3944 / DC_loss : 0.6880\n",
      "- D(x):0.4565 / D(DC(z1)) : 0.4566 / D(DC(z2)) : 0.5027\n",
      "[5/100][0/15]\n",
      "- D_loss : 1.3918 / DC_loss : 0.6492\n",
      "- D(x):0.4981 / D(DC(z1)) : 0.5007 / D(DC(z2)) : 0.5225\n",
      "[5/100][1/15]\n",
      "- D_loss : 1.3899 / DC_loss : 0.6920\n",
      "- D(x):0.5190 / D(DC(z1)) : 0.5201 / D(DC(z2)) : 0.5006\n",
      "[5/100][2/15]\n",
      "- D_loss : 1.3958 / DC_loss : 0.6833\n",
      "- D(x):0.4951 / D(DC(z1)) : 0.4998 / D(DC(z2)) : 0.5049\n",
      "[5/100][3/15]\n",
      "- D_loss : 1.3990 / DC_loss : 0.6869\n",
      "- D(x):0.4969 / D(DC(z1)) : 0.5032 / D(DC(z2)) : 0.5032\n",
      "[5/100][4/15]\n",
      "- D_loss : 1.3932 / DC_loss : 0.6631\n",
      "- D(x):0.4988 / D(DC(z1)) : 0.5022 / D(DC(z2)) : 0.5153\n",
      "[5/100][5/15]\n",
      "- D_loss : 1.3911 / DC_loss : 0.6744\n",
      "- D(x):0.5129 / D(DC(z1)) : 0.5148 / D(DC(z2)) : 0.5095\n",
      "[5/100][6/15]\n",
      "- D_loss : 1.3880 / DC_loss : 0.7043\n",
      "- D(x):0.5084 / D(DC(z1)) : 0.5090 / D(DC(z2)) : 0.4945\n",
      "[5/100][7/15]\n",
      "- D_loss : 1.3869 / DC_loss : 0.6920\n",
      "- D(x):0.4939 / D(DC(z1)) : 0.4941 / D(DC(z2)) : 0.5006\n",
      "[5/100][8/15]\n",
      "- D_loss : 1.3906 / DC_loss : 0.7062\n",
      "- D(x):0.4983 / D(DC(z1)) : 0.5004 / D(DC(z2)) : 0.4935\n",
      "[5/100][9/15]\n",
      "- D_loss : 1.3862 / DC_loss : 0.6695\n",
      "- D(x):0.4911 / D(DC(z1)) : 0.4909 / D(DC(z2)) : 0.5120\n",
      "[5/100][10/15]\n",
      "- D_loss : 1.4029 / DC_loss : 0.7340\n",
      "- D(x):0.5002 / D(DC(z1)) : 0.5083 / D(DC(z2)) : 0.4801\n",
      "[5/100][11/15]\n",
      "- D_loss : 1.3888 / DC_loss : 0.6826\n",
      "- D(x):0.4779 / D(DC(z1)) : 0.4780 / D(DC(z2)) : 0.5053\n",
      "[5/100][12/15]\n",
      "- D_loss : 1.3889 / DC_loss : 0.6535\n",
      "- D(x):0.5007 / D(DC(z1)) : 0.5020 / D(DC(z2)) : 0.5203\n",
      "[5/100][13/15]\n",
      "- D_loss : 1.3879 / DC_loss : 0.6880\n",
      "- D(x):0.5188 / D(DC(z1)) : 0.5188 / D(DC(z2)) : 0.5026\n",
      "[5/100][14/15]\n",
      "- D_loss : 1.3823 / DC_loss : 0.7004\n",
      "- D(x):0.5033 / D(DC(z1)) : 0.5013 / D(DC(z2)) : 0.4964\n",
      "[6/100][0/15]\n",
      "- D_loss : 1.3859 / DC_loss : 0.6875\n",
      "- D(x):0.4951 / D(DC(z1)) : 0.4948 / D(DC(z2)) : 0.5028\n",
      "[6/100][1/15]\n",
      "- D_loss : 1.3920 / DC_loss : 0.6989\n",
      "- D(x):0.4970 / D(DC(z1)) : 0.4998 / D(DC(z2)) : 0.4973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/100][2/15]\n",
      "- D_loss : 1.3909 / DC_loss : 0.6886\n",
      "- D(x):0.4940 / D(DC(z1)) : 0.4960 / D(DC(z2)) : 0.5023\n",
      "[6/100][3/15]\n",
      "- D_loss : 1.3894 / DC_loss : 0.6908\n",
      "- D(x):0.5005 / D(DC(z1)) : 0.5020 / D(DC(z2)) : 0.5012\n",
      "[6/100][4/15]\n",
      "- D_loss : 1.3883 / DC_loss : 0.7009\n",
      "- D(x):0.4995 / D(DC(z1)) : 0.5005 / D(DC(z2)) : 0.4961\n",
      "[6/100][5/15]\n",
      "- D_loss : 1.3888 / DC_loss : 0.6880\n",
      "- D(x):0.4939 / D(DC(z1)) : 0.4951 / D(DC(z2)) : 0.5026\n",
      "[6/100][6/15]\n",
      "- D_loss : 1.3900 / DC_loss : 0.6788\n",
      "- D(x):0.4982 / D(DC(z1)) : 0.5001 / D(DC(z2)) : 0.5072\n",
      "[6/100][7/15]\n",
      "- D_loss : 1.3897 / DC_loss : 0.6862\n",
      "- D(x):0.5048 / D(DC(z1)) : 0.5064 / D(DC(z2)) : 0.5035\n",
      "[6/100][8/15]\n",
      "- D_loss : 1.3872 / DC_loss : 0.6938\n",
      "- D(x):0.5020 / D(DC(z1)) : 0.5024 / D(DC(z2)) : 0.4997\n",
      "[6/100][9/15]\n",
      "- D_loss : 1.3880 / DC_loss : 0.6907\n",
      "- D(x):0.4982 / D(DC(z1)) : 0.4991 / D(DC(z2)) : 0.5012\n",
      "[6/100][10/15]\n",
      "- D_loss : 1.3871 / DC_loss : 0.6921\n",
      "- D(x):0.5005 / D(DC(z1)) : 0.5008 / D(DC(z2)) : 0.5006\n",
      "[6/100][11/15]\n",
      "- D_loss : 1.3893 / DC_loss : 0.6880\n",
      "- D(x):0.4989 / D(DC(z1)) : 0.5004 / D(DC(z2)) : 0.5026\n",
      "[6/100][12/15]\n",
      "- D_loss : 1.3868 / DC_loss : 0.6884\n",
      "- D(x):0.5020 / D(DC(z1)) : 0.5023 / D(DC(z2)) : 0.5024\n",
      "[6/100][13/15]\n",
      "- D_loss : 1.3872 / DC_loss : 0.6941\n",
      "- D(x):0.5018 / D(DC(z1)) : 0.5022 / D(DC(z2)) : 0.4995\n",
      "[6/100][14/15]\n",
      "- D_loss : 1.3860 / DC_loss : 0.6915\n",
      "- D(x):0.4992 / D(DC(z1)) : 0.4991 / D(DC(z2)) : 0.5008\n",
      "[7/100][0/15]\n",
      "- D_loss : 1.3862 / DC_loss : 0.6968\n",
      "- D(x):0.5007 / D(DC(z1)) : 0.5006 / D(DC(z2)) : 0.4982\n",
      "[7/100][1/15]\n",
      "- D_loss : 1.3852 / DC_loss : 0.6991\n",
      "- D(x):0.4982 / D(DC(z1)) : 0.4976 / D(DC(z2)) : 0.4970\n",
      "[7/100][2/15]\n",
      "- D_loss : 1.3841 / DC_loss : 0.7030\n",
      "- D(x):0.4978 / D(DC(z1)) : 0.4967 / D(DC(z2)) : 0.4951\n",
      "[7/100][3/15]\n",
      "- D_loss : 1.3816 / DC_loss : 0.7078\n",
      "- D(x):0.4965 / D(DC(z1)) : 0.4940 / D(DC(z2)) : 0.4928\n",
      "[7/100][4/15]\n",
      "- D_loss : 1.3815 / DC_loss : 0.6952\n",
      "- D(x):0.4940 / D(DC(z1)) : 0.4915 / D(DC(z2)) : 0.4990\n",
      "[7/100][5/15]\n",
      "- D_loss : 1.3775 / DC_loss : 0.7084\n",
      "- D(x):0.5012 / D(DC(z1)) : 0.4968 / D(DC(z2)) : 0.4925\n",
      "[7/100][6/15]\n",
      "- D_loss : 1.3878 / DC_loss : 0.6465\n",
      "- D(x):0.4874 / D(DC(z1)) : 0.4878 / D(DC(z2)) : 0.5239\n",
      "[7/100][7/15]\n",
      "- D_loss : 1.3933 / DC_loss : 0.7190\n",
      "- D(x):0.5209 / D(DC(z1)) : 0.5234 / D(DC(z2)) : 0.4873\n",
      "[7/100][8/15]\n",
      "- D_loss : 1.3845 / DC_loss : 0.6846\n",
      "- D(x):0.4863 / D(DC(z1)) : 0.4849 / D(DC(z2)) : 0.5043\n",
      "[7/100][9/15]\n",
      "- D_loss : 1.3893 / DC_loss : 0.6570\n",
      "- D(x):0.5002 / D(DC(z1)) : 0.5017 / D(DC(z2)) : 0.5184\n",
      "[7/100][10/15]\n",
      "- D_loss : 1.3818 / DC_loss : 0.6965\n",
      "- D(x):0.5168 / D(DC(z1)) : 0.5140 / D(DC(z2)) : 0.4984\n",
      "[7/100][11/15]\n",
      "- D_loss : 1.3844 / DC_loss : 0.7202\n",
      "- D(x):0.4945 / D(DC(z1)) : 0.4933 / D(DC(z2)) : 0.4867\n",
      "[7/100][12/15]\n",
      "- D_loss : 1.3807 / DC_loss : 0.6647\n",
      "- D(x):0.4821 / D(DC(z1)) : 0.4785 / D(DC(z2)) : 0.5144\n",
      "[7/100][13/15]\n",
      "- D_loss : 1.3767 / DC_loss : 0.6678\n",
      "- D(x):0.5090 / D(DC(z1)) : 0.5041 / D(DC(z2)) : 0.5129\n",
      "[7/100][14/15]\n",
      "- D_loss : 1.3148 / DC_loss : 0.5535\n",
      "- D(x):0.5093 / D(DC(z1)) : 0.4726 / D(DC(z2)) : 0.5751\n",
      "[8/100][0/15]\n",
      "- D_loss : 1.4471 / DC_loss : 1.0127\n",
      "- D(x):0.5539 / D(DC(z1)) : 0.5748 / D(DC(z2)) : 0.3633\n",
      "[8/100][1/15]\n",
      "- D_loss : 1.4576 / DC_loss : 0.4028\n",
      "- D(x):0.3636 / D(DC(z1)) : 0.3587 / D(DC(z2)) : 0.6704\n",
      "[8/100][2/15]\n",
      "- D_loss : 1.5147 / DC_loss : 1.0597\n",
      "- D(x):0.6581 / D(DC(z1)) : 0.6624 / D(DC(z2)) : 0.3500\n",
      "[8/100][3/15]\n",
      "- D_loss : 1.4894 / DC_loss : 0.0001\n",
      "- D(x):0.3481 / D(DC(z1)) : 0.3454 / D(DC(z2)) : 0.9999\n",
      "[8/100][4/15]\n",
      "- D_loss : 8.9094 / DC_loss : 3.0914\n",
      "- D(x):0.9999 / D(DC(z1)) : 0.9999 / D(DC(z2)) : 0.0470\n",
      "[8/100][5/15]\n",
      "- D_loss : 3.1906 / DC_loss : 0.0000\n",
      "- D(x):0.0451 / D(DC(z1)) : 0.0456 / D(DC(z2)) : 1.0000\n",
      "[8/100][6/15]\n",
      "- D_loss : 14.7399 / DC_loss : 0.2079\n",
      "- D(x):1.0000 / D(DC(z1)) : 1.0000 / D(DC(z2)) : 0.8126\n",
      "[8/100][7/15]\n",
      "- D_loss : 1.8473 / DC_loss : 5.7554\n",
      "- D(x):0.7918 / D(DC(z1)) : 0.7999 / D(DC(z2)) : 0.0032\n",
      "[8/100][8/15]\n",
      "- D_loss : 6.0230 / DC_loss : 0.4711\n",
      "- D(x):0.0029 / D(DC(z1)) : 0.0034 / D(DC(z2)) : 0.6269\n",
      "[8/100][9/15]\n",
      "- D_loss : 1.4646 / DC_loss : 0.2476\n",
      "- D(x):0.6068 / D(DC(z1)) : 0.6083 / D(DC(z2)) : 0.8020\n",
      "[8/100][10/15]\n",
      "- D_loss : 2.3052 / DC_loss : 1.1268\n",
      "- D(x):0.7672 / D(DC(z1)) : 0.7923 / D(DC(z2)) : 0.4154\n",
      "[8/100][11/15]\n",
      "- D_loss : 1.7146 / DC_loss : 1.2040\n",
      "- D(x):0.3985 / D(DC(z1)) : 0.4100 / D(DC(z2)) : 0.3017\n",
      "[8/100][12/15]\n",
      "- D_loss : 1.6081 / DC_loss : 0.6500\n",
      "- D(x):0.2846 / D(DC(z1)) : 0.2939 / D(DC(z2)) : 0.5226\n",
      "[8/100][13/15]\n",
      "- D_loss : 1.5014 / DC_loss : 0.3898\n",
      "- D(x):0.4672 / D(DC(z1)) : 0.5214 / D(DC(z2)) : 0.6774\n",
      "[8/100][14/15]\n",
      "- D_loss : 1.7848 / DC_loss : 0.8825\n",
      "- D(x):0.5383 / D(DC(z1)) : 0.6881 / D(DC(z2)) : 0.4137\n",
      "[9/100][0/15]\n",
      "- D_loss : 1.2426 / DC_loss : 0.3527\n",
      "- D(x):0.4927 / D(DC(z1)) : 0.4141 / D(DC(z2)) : 0.7028\n",
      "[9/100][1/15]\n",
      "- D_loss : 1.9148 / DC_loss : 0.6003\n",
      "- D(x):0.5011 / D(DC(z1)) : 0.7055 / D(DC(z2)) : 0.5487\n",
      "[9/100][2/15]\n",
      "- D_loss : 1.6212 / DC_loss : 0.8607\n",
      "- D(x):0.4375 / D(DC(z1)) : 0.5466 / D(DC(z2)) : 0.4234\n",
      "[9/100][3/15]\n",
      "- D_loss : 1.4377 / DC_loss : 0.7449\n",
      "- D(x):0.4090 / D(DC(z1)) : 0.4187 / D(DC(z2)) : 0.4752\n",
      "[9/100][4/15]\n",
      "- D_loss : 1.4359 / DC_loss : 0.7688\n",
      "- D(x):0.4489 / D(DC(z1)) : 0.4695 / D(DC(z2)) : 0.4645\n",
      "[9/100][5/15]\n",
      "- D_loss : 1.3626 / DC_loss : 0.7160\n",
      "- D(x):0.4754 / D(DC(z1)) : 0.4602 / D(DC(z2)) : 0.4888\n",
      "[9/100][6/15]\n",
      "- D_loss : 1.3383 / DC_loss : 0.7319\n",
      "- D(x):0.5046 / D(DC(z1)) : 0.4800 / D(DC(z2)) : 0.4812\n",
      "[9/100][7/15]\n",
      "- D_loss : 1.2983 / DC_loss : 0.7387\n",
      "- D(x):0.5183 / D(DC(z1)) : 0.4730 / D(DC(z2)) : 0.4778\n",
      "[9/100][8/15]\n",
      "- D_loss : 1.3132 / DC_loss : 0.6613\n",
      "- D(x):0.5007 / D(DC(z1)) : 0.4625 / D(DC(z2)) : 0.5165\n",
      "[9/100][9/15]\n",
      "- D_loss : 1.2918 / DC_loss : 0.6617\n",
      "- D(x):0.5471 / D(DC(z1)) : 0.4968 / D(DC(z2)) : 0.5173\n",
      "[9/100][10/15]\n",
      "- D_loss : 1.3165 / DC_loss : 0.9606\n",
      "- D(x):0.5402 / D(DC(z1)) : 0.5010 / D(DC(z2)) : 0.3867\n",
      "[9/100][11/15]\n",
      "- D_loss : 1.3010 / DC_loss : 0.9485\n",
      "- D(x):0.4414 / D(DC(z1)) : 0.3772 / D(DC(z2)) : 0.3896\n",
      "[9/100][12/15]\n",
      "- D_loss : 1.1856 / DC_loss : 0.6314\n",
      "- D(x):0.5127 / D(DC(z1)) : 0.3991 / D(DC(z2)) : 0.5356\n",
      "[9/100][13/15]\n",
      "- D_loss : 1.2140 / DC_loss : 0.9267\n",
      "- D(x):0.6188 / D(DC(z1)) : 0.5150 / D(DC(z2)) : 0.3964\n",
      "[9/100][14/15]\n",
      "- D_loss : 1.7001 / DC_loss : 0.3176\n",
      "- D(x):0.2979 / D(DC(z1)) : 0.3836 / D(DC(z2)) : 0.7301\n",
      "[10/100][0/15]\n",
      "- D_loss : 1.6383 / DC_loss : 0.7300\n",
      "- D(x):0.7264 / D(DC(z1)) : 0.7236 / D(DC(z2)) : 0.4823\n",
      "[10/100][1/15]\n",
      "- D_loss : 1.3238 / DC_loss : 0.9674\n",
      "- D(x):0.5069 / D(DC(z1)) : 0.4732 / D(DC(z2)) : 0.3893\n",
      "[10/100][2/15]\n",
      "- D_loss : 1.3063 / DC_loss : 0.7215\n",
      "- D(x):0.4378 / D(DC(z1)) : 0.3735 / D(DC(z2)) : 0.4906\n",
      "[10/100][3/15]\n",
      "- D_loss : 1.4261 / DC_loss : 1.0055\n",
      "- D(x):0.4894 / D(DC(z1)) : 0.5011 / D(DC(z2)) : 0.3761\n",
      "[10/100][4/15]\n",
      "- D_loss : 1.3115 / DC_loss : 0.9437\n",
      "- D(x):0.4381 / D(DC(z1)) : 0.3650 / D(DC(z2)) : 0.3955\n",
      "[10/100][5/15]\n",
      "- D_loss : 1.0760 / DC_loss : 0.9502\n",
      "- D(x):0.5670 / D(DC(z1)) : 0.3914 / D(DC(z2)) : 0.3873\n",
      "[10/100][6/15]\n",
      "- D_loss : 0.9635 / DC_loss : 1.0560\n",
      "- D(x):0.6080 / D(DC(z1)) : 0.3699 / D(DC(z2)) : 0.3690\n",
      "[10/100][7/15]\n",
      "- D_loss : 1.1379 / DC_loss : 1.3468\n",
      "- D(x):0.5154 / D(DC(z1)) : 0.3594 / D(DC(z2)) : 0.2764\n",
      "[10/100][8/15]\n",
      "- D_loss : 0.7279 / DC_loss : 0.5443\n",
      "- D(x):0.6716 / D(DC(z1)) : 0.2482 / D(DC(z2)) : 0.5822\n",
      "[10/100][9/15]\n",
      "- D_loss : 1.0425 / DC_loss : 2.0481\n",
      "- D(x):0.7250 / D(DC(z1)) : 0.5089 / D(DC(z2)) : 0.1347\n",
      "[10/100][10/15]\n",
      "- D_loss : 2.8660 / DC_loss : 0.0286\n",
      "- D(x):0.0719 / D(DC(z1)) : 0.1542 / D(DC(z2)) : 0.9718\n",
      "[10/100][11/15]\n",
      "- D_loss : 3.5535 / DC_loss : 0.5893\n",
      "- D(x):0.9631 / D(DC(z1)) : 0.9683 / D(DC(z2)) : 0.5555\n",
      "[10/100][12/15]\n",
      "- D_loss : 1.2664 / DC_loss : 1.2578\n",
      "- D(x):0.6308 / D(DC(z1)) : 0.5464 / D(DC(z2)) : 0.2899\n",
      "[10/100][13/15]\n",
      "- D_loss : 1.3286 / DC_loss : 1.3572\n",
      "- D(x):0.3975 / D(DC(z1)) : 0.2958 / D(DC(z2)) : 0.2579\n",
      "[10/100][14/15]\n",
      "- D_loss : 1.1737 / DC_loss : 0.3238\n",
      "- D(x):0.4072 / D(DC(z1)) : 0.2360 / D(DC(z2)) : 0.7291\n",
      "[11/100][0/15]\n",
      "- D_loss : 1.6656 / DC_loss : 0.6781\n",
      "- D(x):0.4767 / D(DC(z1)) : 0.5981 / D(DC(z2)) : 0.5098\n",
      "[11/100][1/15]\n",
      "- D_loss : 1.4149 / DC_loss : 0.6529\n",
      "- D(x):0.5004 / D(DC(z1)) : 0.5091 / D(DC(z2)) : 0.5243\n",
      "[11/100][2/15]\n",
      "- D_loss : 1.4029 / DC_loss : 0.6608\n",
      "- D(x):0.4861 / D(DC(z1)) : 0.4887 / D(DC(z2)) : 0.5187\n",
      "[11/100][3/15]\n",
      "- D_loss : 1.3965 / DC_loss : 0.7691\n",
      "- D(x):0.5092 / D(DC(z1)) : 0.5099 / D(DC(z2)) : 0.4645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/100][4/15]\n",
      "- D_loss : 1.2533 / DC_loss : 0.8640\n",
      "- D(x):0.4919 / D(DC(z1)) : 0.4156 / D(DC(z2)) : 0.4231\n",
      "[11/100][5/15]\n",
      "- D_loss : 1.2294 / DC_loss : 0.8116\n",
      "- D(x):0.4931 / D(DC(z1)) : 0.4057 / D(DC(z2)) : 0.4468\n",
      "[11/100][6/15]\n",
      "- D_loss : 1.2428 / DC_loss : 0.8252\n",
      "- D(x):0.5020 / D(DC(z1)) : 0.4201 / D(DC(z2)) : 0.4394\n",
      "[11/100][7/15]\n",
      "- D_loss : 1.2701 / DC_loss : 0.7433\n",
      "- D(x):0.5385 / D(DC(z1)) : 0.4756 / D(DC(z2)) : 0.4764\n",
      "[11/100][8/15]\n",
      "- D_loss : 1.5187 / DC_loss : 0.6078\n",
      "- D(x):0.4298 / D(DC(z1)) : 0.4894 / D(DC(z2)) : 0.5450\n",
      "[11/100][9/15]\n",
      "- D_loss : 1.3092 / DC_loss : 0.7186\n",
      "- D(x):0.5663 / D(DC(z1)) : 0.5214 / D(DC(z2)) : 0.4877\n",
      "[11/100][10/15]\n",
      "- D_loss : 1.2781 / DC_loss : 0.9553\n",
      "- D(x):0.5207 / D(DC(z1)) : 0.4640 / D(DC(z2)) : 0.3848\n",
      "[11/100][11/15]\n",
      "- D_loss : 1.2686 / DC_loss : 0.6004\n",
      "- D(x):0.4274 / D(DC(z1)) : 0.3411 / D(DC(z2)) : 0.5497\n",
      "[11/100][12/15]\n",
      "- D_loss : 1.3748 / DC_loss : 0.8031\n",
      "- D(x):0.5807 / D(DC(z1)) : 0.5617 / D(DC(z2)) : 0.4518\n",
      "[11/100][13/15]\n",
      "- D_loss : 1.2115 / DC_loss : 0.8187\n",
      "- D(x):0.4819 / D(DC(z1)) : 0.3764 / D(DC(z2)) : 0.4448\n",
      "[11/100][14/15]\n",
      "- D_loss : 1.1112 / DC_loss : 0.8151\n",
      "- D(x):0.6167 / D(DC(z1)) : 0.4634 / D(DC(z2)) : 0.4444\n",
      "[12/100][0/15]\n",
      "- D_loss : 1.5367 / DC_loss : 0.6779\n",
      "- D(x):0.3940 / D(DC(z1)) : 0.4515 / D(DC(z2)) : 0.5165\n",
      "[12/100][1/15]\n",
      "- D_loss : 1.1986 / DC_loss : 0.7339\n",
      "- D(x):0.6429 / D(DC(z1)) : 0.5179 / D(DC(z2)) : 0.4915\n",
      "[12/100][2/15]\n",
      "- D_loss : 1.2169 / DC_loss : 1.2897\n",
      "- D(x):0.5968 / D(DC(z1)) : 0.4864 / D(DC(z2)) : 0.2755\n",
      "[12/100][3/15]\n",
      "- D_loss : 1.1034 / DC_loss : 1.2932\n",
      "- D(x):0.4430 / D(DC(z1)) : 0.2497 / D(DC(z2)) : 0.2897\n",
      "[12/100][4/15]\n",
      "- D_loss : 0.9282 / DC_loss : 1.1113\n",
      "- D(x):0.5667 / D(DC(z1)) : 0.2880 / D(DC(z2)) : 0.3525\n",
      "[12/100][5/15]\n",
      "- D_loss : 0.7671 / DC_loss : 0.9910\n",
      "- D(x):0.6817 / D(DC(z1)) : 0.3040 / D(DC(z2)) : 0.4064\n",
      "[12/100][6/15]\n",
      "- D_loss : 0.9006 / DC_loss : 1.0631\n",
      "- D(x):0.7339 / D(DC(z1)) : 0.4180 / D(DC(z2)) : 0.3513\n",
      "[12/100][7/15]\n",
      "- D_loss : 1.3352 / DC_loss : 1.6526\n",
      "- D(x):0.3996 / D(DC(z1)) : 0.3201 / D(DC(z2)) : 0.1964\n",
      "[12/100][8/15]\n",
      "- D_loss : 0.6809 / DC_loss : 0.3484\n",
      "- D(x):0.6598 / D(DC(z1)) : 0.2226 / D(DC(z2)) : 0.7081\n",
      "[12/100][9/15]\n",
      "- D_loss : 1.4115 / DC_loss : 5.6738\n",
      "- D(x):0.8818 / D(DC(z1)) : 0.7199 / D(DC(z2)) : 0.0044\n",
      "[12/100][10/15]\n",
      "- D_loss : 1.4755 / DC_loss : 0.2343\n",
      "- D(x):0.3749 / D(DC(z1)) : 0.0005 / D(DC(z2)) : 0.7979\n",
      "[12/100][11/15]\n",
      "- D_loss : 2.2682 / DC_loss : 1.2988\n",
      "- D(x):0.6663 / D(DC(z1)) : 0.7899 / D(DC(z2)) : 0.2755\n",
      "[12/100][12/15]\n",
      "- D_loss : 1.3911 / DC_loss : 1.9227\n",
      "- D(x):0.3623 / D(DC(z1)) : 0.2802 / D(DC(z2)) : 0.1525\n",
      "[12/100][13/15]\n",
      "- D_loss : 0.9341 / DC_loss : 1.0876\n",
      "- D(x):0.4623 / D(DC(z1)) : 0.1423 / D(DC(z2)) : 0.3537\n",
      "[12/100][14/15]\n",
      "- D_loss : 0.8290 / DC_loss : 2.3622\n",
      "- D(x):0.6658 / D(DC(z1)) : 0.3335 / D(DC(z2)) : 0.0952\n",
      "[13/100][0/15]\n",
      "- D_loss : 0.5242 / DC_loss : 2.1159\n",
      "- D(x):0.6471 / D(DC(z1)) : 0.0829 / D(DC(z2)) : 0.1206\n",
      "[13/100][1/15]\n",
      "- D_loss : 0.2559 / DC_loss : 1.1779\n",
      "- D(x):0.8659 / D(DC(z1)) : 0.1056 / D(DC(z2)) : 0.3162\n",
      "[13/100][2/15]\n",
      "- D_loss : 0.3384 / DC_loss : 2.2524\n",
      "- D(x):0.9226 / D(DC(z1)) : 0.2250 / D(DC(z2)) : 0.1119\n",
      "[13/100][3/15]\n",
      "- D_loss : 0.2191 / DC_loss : 2.9077\n",
      "- D(x):0.8759 / D(DC(z1)) : 0.0791 / D(DC(z2)) : 0.0546\n",
      "[13/100][4/15]\n",
      "- D_loss : 0.1728 / DC_loss : 2.9560\n",
      "- D(x):0.8701 / D(DC(z1)) : 0.0305 / D(DC(z2)) : 0.0531\n",
      "[13/100][5/15]\n",
      "- D_loss : 0.1295 / DC_loss : 3.2230\n",
      "- D(x):0.9262 / D(DC(z1)) : 0.0513 / D(DC(z2)) : 0.0433\n",
      "[13/100][6/15]\n",
      "- D_loss : 0.1151 / DC_loss : 0.2041\n",
      "- D(x):0.9453 / D(DC(z1)) : 0.0569 / D(DC(z2)) : 0.8160\n",
      "[13/100][7/15]\n",
      "- D_loss : 1.6301 / DC_loss : 1.5775\n",
      "- D(x):0.9482 / D(DC(z1)) : 0.7873 / D(DC(z2)) : 0.3793\n",
      "[13/100][8/15]\n",
      "- D_loss : 2.6839 / DC_loss : 1.8011\n",
      "- D(x):0.3115 / D(DC(z1)) : 0.4064 / D(DC(z2)) : 0.2147\n",
      "[13/100][9/15]\n",
      "- D_loss : 1.7849 / DC_loss : 0.5126\n",
      "- D(x):0.2493 / D(DC(z1)) : 0.0831 / D(DC(z2)) : 0.5992\n",
      "[13/100][10/15]\n",
      "- D_loss : 1.1400 / DC_loss : 0.7802\n",
      "- D(x):0.6752 / D(DC(z1)) : 0.5240 / D(DC(z2)) : 0.5302\n",
      "[13/100][11/15]\n",
      "- D_loss : 1.1875 / DC_loss : 2.6105\n",
      "- D(x):0.6502 / D(DC(z1)) : 0.4475 / D(DC(z2)) : 0.1256\n",
      "[13/100][12/15]\n",
      "- D_loss : 0.5567 / DC_loss : 2.1974\n",
      "- D(x):0.6667 / D(DC(z1)) : 0.1023 / D(DC(z2)) : 0.1810\n",
      "[13/100][13/15]\n",
      "- D_loss : 0.4276 / DC_loss : 6.1293\n",
      "- D(x):0.7805 / D(DC(z1)) : 0.1473 / D(DC(z2)) : 0.0024\n",
      "[13/100][14/15]\n",
      "- D_loss : 0.9094 / DC_loss : 0.6223\n",
      "- D(x):0.4131 / D(DC(z1)) : 0.0013 / D(DC(z2)) : 0.5469\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_DCGAN(epoch, learning_DC_per_D = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_gen_imgs():\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    ims=[[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "    HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_gen_imgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trian : izif E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DC.eval()\n",
    "D.eval()\n",
    "\n",
    "kappa = 1.0\n",
    "EC_losses = []\n",
    "\n",
    "iters = 0\n",
    "AE_img_list = []\n",
    "\n",
    "def train_AE(epoch):\n",
    "    global epochs\n",
    "    global iters\n",
    "    global EC_losses\n",
    "    global AE_img_list\n",
    "    \n",
    "    # 인덱스 0부터 세기 시작\n",
    "    # data[0].size():64x1x64x64(image) / data[1].size():64(label)\n",
    "    for i,data in enumerate(data_loader,0):\n",
    "        \n",
    "        real_imgs = data[0].to(device)\n",
    "        \n",
    "        EC_optimizer.zero_grad()\n",
    "        \n",
    "        EC_validity = EC(real_imgs)\n",
    "        \n",
    "        fake_imgs = DC(EC_validity)\n",
    "        \n",
    "        _, real_features = D.forward(real_imgs)\n",
    "        _, fake_features = D.forward(fake_imgs)\n",
    "        \n",
    "        \n",
    "        # izif architecture\n",
    "        imgs_loss = AE_criterion(real_imgs, fake_imgs)\n",
    "        features_loss = AE_criterion(real_features, fake_features)\n",
    "        EC_loss = imgs_loss + kappa*features_loss\n",
    "        \n",
    "        EC_loss.backward()\n",
    "        EC_optimizer.step()\n",
    "        \n",
    "        # =============================================================\n",
    "        # print\n",
    "        # =============================================================\n",
    "        print('[%d/%d][%d/%d]\\n- E_loss: %.4f\\n'\n",
    "              %(epoch+1, epochs, i, len(data_loader), EC_loss.item()))\n",
    "        \n",
    "        # Save Losses for plotting later\n",
    "        EC_losses.append(EC_loss.item())\n",
    "        \n",
    "        #Check how the generator is doing by saving G's output on noise_z\n",
    "        if (iters % 500 == 0) or ((epoch == epochs-1) and (i == len(data_loader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = DC(EC_validity).detach().cpu()\n",
    "            AE_img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "            \n",
    "        iters += 1\n",
    "        \n",
    "#torch.save(E.state_dict(), 'E.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_AE(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_loss():\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "    plt.plot(DC_losses, label=\"G\")\n",
    "    plt.plot(D_losses, label=\"D\")\n",
    "    plt.plot(EC_losses, label=\"E\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data_root = \"../../dataset/test/test_DualPhaseSteel\"\n",
    "Ti64_test_data_root = \"../../dataset/test/test_Ti64\"\n",
    "\n",
    "test_data_set = dataset.ImageFolder(root = Ti64_test_data_root, # test_data_root,\n",
    "                           transform = transforms.Compose([\n",
    "                                  transforms.Resize(img_size),\n",
    "                                  transforms.CenterCrop(img_size),\n",
    "                                  torchvision.transforms.Grayscale(channel),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5,),(0.5,))\n",
    "                              ]))\n",
    "\n",
    "# 배치로 나누고 셔플하기\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data_set, batch_size = 1,\n",
    "                                              shuffle = False, num_workers = workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이상 픽셀 수 확인 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_el_not_0(diff_img):\n",
    "    count_el_not_0 = 0\n",
    "    \n",
    "    col_size = diff_img.shape[0]\n",
    "    row_size = diff_img.shape[1]\n",
    "    \n",
    "    #print(col_size, row_size)\n",
    "    \n",
    "    for col in range(col_size):\n",
    "        for row in range(row_size):\n",
    "            if diff_img[col][row] != 0:\n",
    "                count_el_not_0 += 1\n",
    "                \n",
    "    return count_el_not_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# img 비교 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_imgs(real_img, generated_img, i, score, reverse=False, threshold=50):\n",
    "    real_img = real_img.cpu().data.numpy().reshape(img_size, img_size) * 255\n",
    "    generated_img = generated_img.cpu().data.numpy().reshape(img_size, img_size) * 255\n",
    "    \n",
    "    negative = np.zeros_like(real_img)\n",
    "\n",
    "    if not reverse:\n",
    "        diff_img = real_img - generated_img\n",
    "    else:\n",
    "        diff_img = generated_img - real_img\n",
    "\n",
    "    diff_img[diff_img <= threshold] = 0\n",
    "\n",
    "    # 분율 추출\n",
    "    diff_cnts.append(count_el_not_0(diff_img))\n",
    "    # 분산 추출\n",
    "    diff_points.append(np.where(diff_img > threshold))\n",
    "    \n",
    "    anomaly_img = np.zeros(shape=(img_size, img_size, 3))\n",
    "    anomaly_img[:, :, 0] = real_img - diff_img\n",
    "    anomaly_img[:, :, 1] = real_img - diff_img\n",
    "    anomaly_img[:, :, 2] = real_img - diff_img\n",
    "    anomaly_img[:, :, 0] = anomaly_img[:,:,0] + diff_img\n",
    "    anomaly_img = anomaly_img.astype(np.uint8)\n",
    "\n",
    "    # anomaly_img 추출\n",
    "    anomaly_imgs.append(anomaly_img)\n",
    "    \n",
    "    fig, plots = plt.subplots(1, 4)\n",
    "\n",
    "    fig.suptitle(f'Anomaly - (anomaly score: {score:.4})')\n",
    "    \n",
    "    fig.set_figwidth(9)\n",
    "    fig.set_tight_layout(True)\n",
    "    plots = plots.reshape(-1)\n",
    "    plots[0].imshow(real_img, cmap='gray', label = \"real\")\n",
    "    plots[1].imshow(generated_img, cmap='gray')\n",
    "    plots[2].imshow(diff_img, cmap='gray')\n",
    "    plots[3].imshow(anomaly_img)\n",
    "    \n",
    "    plots[0].set_title('real')\n",
    "    plots[1].set_title('generated')\n",
    "    plots[2].set_title('difference')\n",
    "    plots[3].set_title('Anomaly Detection')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diff_cnts = []\n",
    "diff_points = []\n",
    "anomaly_imgs = []\n",
    "\n",
    "ano_criterion = nn.MSELoss()\n",
    "DC.eval()\n",
    "D.eval()\n",
    "EC.eval()\n",
    "\n",
    "# with open(\"score.csv\", \"w\") as f:\n",
    "#         f.write(\"label,img_distance,anomaly_score,z_distance\\n\")\n",
    "\n",
    "for i, data in enumerate(test_data_loader, 0):\n",
    "    real_img = data[0].to(device)\n",
    "\n",
    "    real_z = EC(real_img) # 진짜 이미지의 latent vector\n",
    "    fake_img = DC(real_z) # DC에 넣어서 가짜 이미지 생성.\n",
    "    fake_z = EC(fake_img) # torch.Size([1, 100]) --> latent 진짜 이미지와 매핑된 가짜 이미지의 latent vector\n",
    "\n",
    "    _, real_feature = D.forward(real_img) # 1, 256\n",
    "    _, fake_feature = D.forward(fake_img)\n",
    "\n",
    "    img_distance = ano_criterion(fake_img, real_img)\n",
    "    loss_feature = ano_criterion(fake_feature, real_feature)\n",
    "\n",
    "    anomaly_score = img_distance + kappa*loss_feature\n",
    "\n",
    "    z_distance = ano_criterion(fake_z, real_z)\n",
    "    \n",
    "#     with open(\"score.csv\", \"a\") as f:\n",
    "#             f.write(f\"{label.item()},{img_distance},\"\n",
    "#                     f\"{anomaly_score},{z_distance}\\n\")\n",
    "            \n",
    "#     print(f\"{label.item()}, {img_distance}, \"\n",
    "#           f\"{anomaly_score}, {z_distance}\\n\")\n",
    "    compare_imgs(real_img, fake_img, i, anomaly_score, reverse = False, threshold = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분율 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_cnts = np.array(diff_cnts)\n",
    "\n",
    "diff_fraction = diff_cnts / img_size ** 2\n",
    "\n",
    "print(diff_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(diff_fraction)/len(diff_fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분산 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from extended_int import int_inf\n",
    "\n",
    "corr_coeffis = []\n",
    "corr_p_vals = []\n",
    "\n",
    "def cal_corr_coeffis():\n",
    "    for idx in range(len(test_data_loader)):\n",
    "        x_points = diff_points[idx][0]\n",
    "        y_points = diff_points[idx][1]\n",
    "        \n",
    "        \n",
    "        if len(x_points) > 0:\n",
    "            corr_coeffi, corr_p_val = stats.pearsonr(x_points, y_points)\n",
    "        else:\n",
    "            corr_coeffi, corr_p_val = -int_inf, -int_inf\n",
    "        \n",
    "        corr_coeffis.append(corr_coeffi)\n",
    "        corr_p_vals.append(corr_p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_corr_coeffis()\n",
    "\n",
    "print(corr_coeffis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장 및 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = \"./pretrained/pretrained.pth\"\n",
    "\n",
    "def save_pretrained():\n",
    "    pretrained = {\n",
    "        \"D\" : D.state_dict(),\n",
    "        \"DC\" : DC.state_dict(),\n",
    "        \"EC\" : EC.state_dict()\n",
    "    }\n",
    "\n",
    "    if not os.path.isdir(\"pretrained\"):\n",
    "        os.mkdir(\"pretrained\")\n",
    "    torch.save(pretrained, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_D = Discriminator().to(device)\n",
    "pretrained_DC = Decoder().to(device)\n",
    "pretrained_EC = Encoder().to(device)\n",
    "\n",
    "def load_pretrained():\n",
    "    global pretrained_D\n",
    "    global pretrained_DC\n",
    "    global pretrained_EC\n",
    "    \n",
    "    assert os.path.isdir(\"pretrained\"), \"Error : no pretrained dir found!\"\n",
    "    \n",
    "    pretrained = torch.load(save_file)\n",
    "    \n",
    "    pretrained_D.load_state_dict(pretrained[\"D\"])\n",
    "    pretrained_DC.load_state_dict(pretrained[\"DC\"])\n",
    "    pretrained_EC.load_state_dict(pretrained[\"EC\"])\n",
    "    \n",
    "    #print(\"pretrained_D :\", pretrained_D)\n",
    "    #print(\"pretrained_G :\", pretrained_DC)\n",
    "    #print(\"pretrained_E :\", pretrained_EC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    ano_criterion = nn.MSELoss()\n",
    "    pretrained_DC.eval()\n",
    "    pretrained_D.eval()\n",
    "    pretrained_EC.eval()\n",
    "\n",
    "    # with open(\"score.csv\", \"w\") as f:\n",
    "    #         f.write(\"label,img_distance,anomaly_score,z_distance\\n\")\n",
    "\n",
    "    for i, data in enumerate(test_data_loader, 0):\n",
    "        real_img = data[0].to(device)\n",
    "\n",
    "        real_z = pretrained_EC(real_img) # 진짜 이미지의 latent vector\n",
    "        fake_img = pretrained_DC(real_z) # DC에 넣어서 가짜 이미지 생성.\n",
    "        fake_z = pretrained_EC(fake_img) # torch.Size([1, 100]) --> latent 진짜 이미지와 매핑된 가짜 이미지의 latent vector\n",
    "\n",
    "        _, real_feature = pretrained_D.forward(real_img) # 1, 256\n",
    "        _, fake_feature = pretrained_D.forward(fake_img)\n",
    "\n",
    "        img_distance = ano_criterion(fake_img, real_img)\n",
    "        loss_feature = ano_criterion(fake_feature, real_feature)\n",
    "\n",
    "        anomaly_score = img_distance + kappa*loss_feature\n",
    "\n",
    "        z_distance = ano_criterion(fake_z, real_z)\n",
    "\n",
    "    #     with open(\"score.csv\", \"a\") as f:\n",
    "    #             f.write(f\"{label.item()},{img_distance},\"\n",
    "    #                     f\"{anomaly_score},{z_distance}\\n\")\n",
    "\n",
    "    #     print(f\"{label.item()}, {img_distance}, \"\n",
    "    #           f\"{anomaly_score}, {z_distance}\\n\")\n",
    "        compare_imgs(real_img, fake_img, i, anomaly_score, reverse = False, threshold = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_cnts = []\n",
    "diff_points = []\n",
    "anomaly_imgs = []\n",
    "\n",
    "corr_coeffis = []\n",
    "corr_p_vals = []\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_cnts = np.array(diff_cnts)\n",
    "\n",
    "diff_fraction = diff_cnts / img_size ** 2\n",
    "\n",
    "print(diff_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_corr_coeffis()\n",
    "\n",
    "print(corr_coeffis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# anomaly detection 이미지 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 저장 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def save_imgs(folder, imgs):\n",
    "    if not os.path.isdir(\"anomaly_imgs\"):\n",
    "        os.mkdir(\"anomaly_imgs\")\n",
    "    \n",
    "    for i in range(len(imgs)):\n",
    "        cv2.imwrite('%s/%d.png' %(folder,i), imgs[i]) #이미지 저장할 경로 설정을 여기서 한다.\n",
    "    print(\"image saving complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_imgs(\"./anomaly_imgs\", anomaly_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 티타늄(Ti64) 상대 밀도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ti64_density = 4.43\n",
    "\n",
    "Ti64_rel_densitys = np.array([])\n",
    "\n",
    "Ti64_rel_densitys = diff_fraction * Ti64_density\n",
    "\n",
    "print(Ti64_rel_densitys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
